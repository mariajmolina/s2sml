Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00034: reducing learning rate of group 0 to 1.3549e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1134, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1000, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0821, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0754, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1065, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0567, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0924, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0715, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0767, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0346, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0529, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0734, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0885, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0719, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0446, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0506, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0437, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0364, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1306, device='cuda:0')
32
we have a negative! tensor(-0.2817, device='cuda:0')
32
we have a negative! tensor(-0.1675, device='cuda:0')
8
we have a negative! tensor(-0.4083, device='cuda:0')
32
we have a negative! tensor(-0.1307, device='cuda:0')
32
we have a negative! tensor(-0.2807, device='cuda:0')
32
we have a negative! tensor(-0.1861, device='cuda:0')
32
we have a negative! tensor(-0.2398, device='cuda:0')
29
we have a negative! tensor(-0.2208, device='cuda:0')
we have a negative! tensor(-0.0728, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0639, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0338, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0222, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0144, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0479, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0501, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0096, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0232, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0034, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0035, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0107, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0171, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0760, device='cuda:0')
we have a negative! tensor(-0.1857, device='cuda:0')
we have a negative! tensor(-0.0954, device='cuda:0')
we have a negative! tensor(-0.2264, device='cuda:0')
we have a negative! tensor(-0.1017, device='cuda:0')
we have a negative! tensor(-0.1889, device='cuda:0')
we have a negative! tensor(-0.1008, device='cuda:0')
we have a negative! tensor(-0.1468, device='cuda:0')
we have a negative! tensor(-0.1392, device='cuda:0')
we have a negative! tensor(-0.0303, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00041: reducing learning rate of group 0 to 3.5669e-07.
32
32
32
8
32
32
32
32
29
Epoch 00049: reducing learning rate of group 0 to 3.5669e-08.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 4.6344e-06.
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 4.6344e-07.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 4.6344e-08.
Epoch 00029: reducing learning rate of group 0 to 4.6344e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.2417, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 4.0266e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 4.0266e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.5477e-04.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 1.5477e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 2.8074e-05.
32
32
32
8
32
32
32
32
29
Epoch 00030: reducing learning rate of group 0 to 2.8074e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1110, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0177, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1348, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0309, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0314, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0081, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.4364, device='cuda:0')
32
we have a negative! tensor(-0.5514, device='cuda:0')
32
we have a negative! tensor(-0.5225, device='cuda:0')
8
we have a negative! tensor(-0.6106, device='cuda:0')
32
we have a negative! tensor(-0.5015, device='cuda:0')
32
we have a negative! tensor(-0.5952, device='cuda:0')
32
we have a negative! tensor(-0.5010, device='cuda:0')
32
we have a negative! tensor(-0.5301, device='cuda:0')
29
we have a negative! tensor(-0.5209, device='cuda:0')
we have a negative! tensor(-0.0394, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0351, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0045, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-1.4591e-05, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0176, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1088, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0126, device='cuda:0')
we have a negative! tensor(-0.0047, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0114, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0208, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0157, device='cuda:0')
we have a negative! tensor(-0.0673, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00037: reducing learning rate of group 0 to 1.4011e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0552, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 1.2587e-04.
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 1.2587e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 1.2587e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00007: reducing learning rate of group 0 to 1.1976e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0538, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 2.5544e-05.
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 2.5544e-06.
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 2.5544e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 6.5571e-04.
Epoch 00015: reducing learning rate of group 0 to 6.5571e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
Epoch 00005: reducing learning rate of group 0 to 5.8765e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00058: reducing learning rate of group 0 to 5.8765e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0606, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0445, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0463, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0082, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0198, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0293, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0164, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0319, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0429, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0280, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0297, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0712, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0594, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0354, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0140, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0882, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0214, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0338, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0315, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0393, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0124, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0384, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0255, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0336, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0523, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0047, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0237, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0527, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0267, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0672, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0635, device='cuda:0')
we have a negative! tensor(-0.0388, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0158, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0323, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0562, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0633, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0712, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0462, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0381, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0207, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0367, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0599, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0399, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0672, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0552, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0246, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0219, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1265, device='cuda:0')
we have a negative! tensor(-0.2494, device='cuda:0')
we have a negative! tensor(-0.0378, device='cuda:0')
we have a negative! tensor(-0.2225, device='cuda:0')
we have a negative! tensor(-0.1782, device='cuda:0')
we have a negative! tensor(-0.1300, device='cuda:0')
we have a negative! tensor(-0.0341, device='cuda:0')
we have a negative! tensor(-0.2224, device='cuda:0')
we have a negative! tensor(-0.0822, device='cuda:0')
we have a negative! tensor(-0.0083, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0710, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0770, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0494, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0398, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0534, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0683, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0624, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1169, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0628, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0764, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1256, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0737, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1119, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0769, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0776, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0')
we have a negative! tensor(-0.1997, device='cuda:0')
we have a negative! tensor(-0.0714, device='cuda:0')
we have a negative! tensor(-0.0018, device='cuda:0')
we have a negative! tensor(-0.1070, device='cuda:0')
we have a negative! tensor(-0.0979, device='cuda:0')
we have a negative! tensor(-0.0466, device='cuda:0')
we have a negative! tensor(-0.0167, device='cuda:0')
we have a negative! tensor(-0.0608, device='cuda:0')
we have a negative! tensor(-0.0688, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0770, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1227, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0934, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0800, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0774, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0969, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1060, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0716, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0653, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0976, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0493, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0764, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0441, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0604, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0736, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0574, device='cuda:0')
we have a negative! tensor(-0.0351, device='cuda:0')
we have a negative! tensor(-0.0536, device='cuda:0')
Epoch 00005: reducing learning rate of group 0 to 3.9485e-06.
we have a negative! tensor(-0.0847, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0732, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0990, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0810, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0738, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0694, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0618, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0642, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0855, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0513, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0364, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1190, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0490, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0611, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0711, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0023, device='cuda:0')
32
we have a negative! tensor(-0.0426, device='cuda:0')
32
we have a negative! tensor(-0.0679, device='cuda:0')
8
32
we have a negative! tensor(-0.0396, device='cuda:0')
32
we have a negative! tensor(-0.0162, device='cuda:0')
32
we have a negative! tensor(-0.0610, device='cuda:0')
32
29
we have a negative! tensor(-0.0166, device='cuda:0')
we have a negative! tensor(-0.0704, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0659, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0868, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0638, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0328, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0828, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0921, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0490, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0589, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0783, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0268, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0582, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0908, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0825, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0407, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0477, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0690, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0243, device='cuda:0')
we have a negative! tensor(-0.0429, device='cuda:0')
we have a negative! tensor(-0.0660, device='cuda:0')
we have a negative! tensor(-0.0363, device='cuda:0')
we have a negative! tensor(-0.0114, device='cuda:0')
we have a negative! tensor(-0.0648, device='cuda:0')
we have a negative! tensor(-0.0281, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1186, device='cuda:0')
32
we have a negative! tensor(-0.0658, device='cuda:0')
32
we have a negative! tensor(-0.0474, device='cuda:0')
8
we have a negative! tensor(-0.0529, device='cuda:0')
32
32
32
we have a negative! tensor(-0.0484, device='cuda:0')
32
we have a negative! tensor(-0.0505, device='cuda:0')
29
we have a negative! tensor(-0.0288, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00054: reducing learning rate of group 0 to 2.9512e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 8.6025e-05.
32
32
32
8
32
32
32
32
29
Epoch 00024: reducing learning rate of group 0 to 8.6025e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0014, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0199, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0220, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0396, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0738, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0153, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0334, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0591, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0626, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0069, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0747, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0399, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0252, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0745, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0647, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0164, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0215, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0773, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0631, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0260, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0272, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0470, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1302, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0669, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0391, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0702, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0928, device='cuda:0')
we have a negative! tensor(-0.0065, device='cuda:0')
we have a negative! tensor(-0.0874, device='cuda:0')
we have a negative! tensor(-0.0437, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0378, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0765, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0311, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-5.4890e-05, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0211, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0070, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0472, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0384, device='cuda:0')
we have a negative! tensor(-0.2404, device='cuda:0')
we have a negative! tensor(-0.1572, device='cuda:0')
we have a negative! tensor(-0.1030, device='cuda:0')
we have a negative! tensor(-0.0325, device='cuda:0')
Epoch 00005: reducing learning rate of group 0 to 2.1089e-07.
we have a negative! tensor(-0.0448, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0207, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0606, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0845, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0725, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1225, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0583, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0677, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0644, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0282, device='cuda:0', grad_fn=<SumBackward0>)
32
32
we have a negative! tensor(-0.0626, device='cuda:0')
32
8
we have a negative! tensor(-0.1815, device='cuda:0')
32
we have a negative! tensor(-0.1462, device='cuda:0')
32
we have a negative! tensor(-0.1728, device='cuda:0')
32
we have a negative! tensor(-0.0562, device='cuda:0')
32
we have a negative! tensor(-0.0131, device='cuda:0')
29
we have a negative! tensor(-0.0115, device='cuda:0')
we have a negative! tensor(-0.0523, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0384, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1193, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0244, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0275, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0235, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0099, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0365, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0601, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0533, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0261, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0527, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0528, device='cuda:0')
we have a negative! tensor(-0.1895, device='cuda:0')
we have a negative! tensor(-0.1568, device='cuda:0')
we have a negative! tensor(-0.1779, device='cuda:0')
we have a negative! tensor(-0.0544, device='cuda:0')
we have a negative! tensor(-0.0117, device='cuda:0')
we have a negative! tensor(-0.0076, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1108, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 8.8939e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 8.8939e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
we have a negative! tensor(-0.0443, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0440, device='cuda:0')
32
29
we have a negative! tensor(-0.0070, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 3.7809e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 3.7809e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0662, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0457, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0253, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0435, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0484, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0375, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0640, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0363, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0268, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0335, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0362, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0377, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0314, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0430, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0402, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0654, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0330, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0744, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0580, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0248, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0463, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0472, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
we have a negative! tensor(-0.0004, device='cuda:0')
32
29
we have a negative! tensor(-0.0757, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0583, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0851, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0843, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0449, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0450, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0603, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0615, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0349, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0567, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0612, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0210, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0414, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0428, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0078, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0343, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0616, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0385, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0422, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0632, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0164, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0124, device='cuda:0')
we have a negative! tensor(-0.0199, device='cuda:0')
we have a negative! tensor(-0.0516, device='cuda:0')
we have a negative! tensor(-0.0138, device='cuda:0')
we have a negative! tensor(-0.0204, device='cuda:0')
we have a negative! tensor(-0.0287, device='cuda:0')
we have a negative! tensor(-0.0201, device='cuda:0')
we have a negative! tensor(-0.0479, device='cuda:0')
we have a negative! tensor(-0.0471, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0246, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0473, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0467, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0812, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0097, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0462, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0077, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0308, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0259, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0610, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0536, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0269, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0860, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0486, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0371, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0551, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0414, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0293, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0525, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0435, device='cuda:0')
we have a negative! tensor(-0.0851, device='cuda:0')
we have a negative! tensor(-0.0841, device='cuda:0')
we have a negative! tensor(-0.0526, device='cuda:0')
we have a negative! tensor(-0.0828, device='cuda:0')
we have a negative! tensor(-0.1382, device='cuda:0')
we have a negative! tensor(-0.0543, device='cuda:0')
we have a negative! tensor(-0.0162, device='cuda:0')
we have a negative! tensor(-0.0316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0246, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0285, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0284, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0692, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0058, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0332, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0157, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0157, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0133, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0200, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0168, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0225, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0274, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0413, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0199, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0331, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0138, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0043, device='cuda:0')
we have a negative! tensor(-0.0426, device='cuda:0')
we have a negative! tensor(-0.0689, device='cuda:0')
we have a negative! tensor(-0.1312, device='cuda:0')
we have a negative! tensor(-0.1134, device='cuda:0')
we have a negative! tensor(-0.0612, device='cuda:0')
we have a negative! tensor(-0.0596, device='cuda:0')
we have a negative! tensor(-0.0490, device='cuda:0')
we have a negative! tensor(-0.0571, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 2.5069e-07.
we have a negative! tensor(-0.0312, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0250, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0308, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0479, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0545, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0101, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0260, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0246, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0347, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0228, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0089, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0228, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0589, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0137, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0118, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0046, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0431, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0677, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0368, device='cuda:0')
we have a negative! tensor(-0.0855, device='cuda:0')
we have a negative! tensor(-0.0518, device='cuda:0')
we have a negative! tensor(-0.0445, device='cuda:0')
we have a negative! tensor(-0.0709, device='cuda:0')
we have a negative! tensor(-0.1157, device='cuda:0')
we have a negative! tensor(-0.0604, device='cuda:0')
we have a negative! tensor(-0.0245, device='cuda:0')
we have a negative! tensor(-0.0813, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0225, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0378, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0192, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0306, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0772, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0186, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0121, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0306, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0136, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0134, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0130, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0270, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0073, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0595, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0406, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0172, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0051, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0338, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0342, device='cuda:0', grad_fn=<SumBackward0>)
32
32
we have a negative! tensor(-0.0253, device='cuda:0')
32
we have a negative! tensor(-0.0856, device='cuda:0')
8
we have a negative! tensor(-0.1132, device='cuda:0')
32
we have a negative! tensor(-0.0724, device='cuda:0')
32
we have a negative! tensor(-0.0715, device='cuda:0')
32
we have a negative! tensor(-0.1319, device='cuda:0')
32
we have a negative! tensor(-0.0652, device='cuda:0')
29
we have a negative! tensor(-0.0436, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00020: reducing learning rate of group 0 to 4.4091e-04.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00006: reducing learning rate of group 0 to 2.3034e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 2.3034e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
Epoch 00004: reducing learning rate of group 0 to 4.6688e-04.
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
8
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
29
we have constant predictions!
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0038, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0045, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0222, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0075, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0034, device='cuda:0')
we have a negative! tensor(-0.0237, device='cuda:0')
we have a negative! tensor(-0.0140, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0155, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0320, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0365, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0150, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0210, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0310, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0167, device='cuda:0')
we have a negative! tensor(-0.0283, device='cuda:0')
we have a negative! tensor(-0.0197, device='cuda:0')
we have a negative! tensor(-0.0382, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0158, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0253, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0227, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0154, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0028, device='cuda:0', grad_fn=<SumBackward0>)
Epoch 00004: reducing learning rate of group 0 to 3.2432e-06.
we have a negative! tensor(-0.0027, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0064, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0154, device='cuda:0')
we have a negative! tensor(-0.0124, device='cuda:0')
we have a negative! tensor(-0.0138, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0323, device='cuda:0')
32
32
we have a negative! tensor(-0.0581, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0371, device='cuda:0')
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 2.8366e-04.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1186, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00038: reducing learning rate of group 0 to 1.9535e-05.
32
32
32
8
32
32
32
32
29
Epoch 00042: reducing learning rate of group 0 to 1.9535e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0714, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00007: reducing learning rate of group 0 to 2.7569e-04.
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 2.7569e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0477, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0736, device='cuda:0')
32
we have a negative! tensor(-0.0956, device='cuda:0')
32
8
we have a negative! tensor(-0.0232, device='cuda:0')
32
we have a negative! tensor(-0.0105, device='cuda:0')
32
we have a negative! tensor(-0.0331, device='cuda:0')
32
32
we have a negative! tensor(-0.0327, device='cuda:0')
29
we have a negative! tensor(-0.0318, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 2.6120e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 3.2599e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 3.2599e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.2157, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 6.9020e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1185, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1382, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1314, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1131, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1310, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1282, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1329, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1274, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.1295, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1235, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1320, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1305, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1383, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1280, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1257, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1256, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0799, device='cuda:0')
we have a negative! tensor(-0.1241, device='cuda:0')
we have a negative! tensor(-0.0991, device='cuda:0')
we have a negative! tensor(-0.1891, device='cuda:0')
we have a negative! tensor(-0.0993, device='cuda:0')
we have a negative! tensor(-0.1370, device='cuda:0')
we have a negative! tensor(-0.1040, device='cuda:0')
we have a negative! tensor(-0.1318, device='cuda:0')
we have a negative! tensor(-0.1368, device='cuda:0')
we have a negative! tensor(-0.1447, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1210, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1237, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1442, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1502, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1303, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1378, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1440, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2249, device='cuda:0')
we have a negative! tensor(-0.1719, device='cuda:0')
we have a negative! tensor(-0.2198, device='cuda:0')
we have a negative! tensor(-0.0361, device='cuda:0')
we have a negative! tensor(-0.2309, device='cuda:0')
we have a negative! tensor(-0.1679, device='cuda:0')
we have a negative! tensor(-0.1994, device='cuda:0')
we have a negative! tensor(-0.1382, device='cuda:0')
we have a negative! tensor(-0.1877, device='cuda:0')
we have a negative! tensor(-0.1376, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1164, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1341, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1339, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1285, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1421, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1319, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1021, device='cuda:0')
we have a negative! tensor(-0.1815, device='cuda:0')
we have a negative! tensor(-0.1635, device='cuda:0')
we have a negative! tensor(-0.1780, device='cuda:0')
we have a negative! tensor(-0.1491, device='cuda:0')
we have a negative! tensor(-0.1778, device='cuda:0')
we have a negative! tensor(-0.1688, device='cuda:0')
we have a negative! tensor(-0.1003, device='cuda:0')
we have a negative! tensor(-0.1609, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 1.3351e-07.
we have a negative! tensor(-0.1312, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1413, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1252, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1491, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1372, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1233, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1342, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1648, device='cuda:0')
we have a negative! tensor(-0.2113, device='cuda:0')
we have a negative! tensor(-0.2160, device='cuda:0')
we have a negative! tensor(-0.2165, device='cuda:0')
we have a negative! tensor(-0.1642, device='cuda:0')
we have a negative! tensor(-0.2431, device='cuda:0')
we have a negative! tensor(-0.1499, device='cuda:0')
we have a negative! tensor(-0.2067, device='cuda:0')
we have a negative! tensor(-0.2240, device='cuda:0')
we have a negative! tensor(-0.1324, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1267, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1383, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1314, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1400, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1140, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1348, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1415, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1181, device='cuda:0')
32
we have a negative! tensor(-0.1516, device='cuda:0')
32
we have a negative! tensor(-0.1570, device='cuda:0')
8
we have a negative! tensor(-0.2463, device='cuda:0')
32
we have a negative! tensor(-0.1634, device='cuda:0')
32
we have a negative! tensor(-0.2192, device='cuda:0')
32
we have a negative! tensor(-0.1401, device='cuda:0')
32
we have a negative! tensor(-0.1782, device='cuda:0')
29
we have a negative! tensor(-0.2075, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0036, device='cuda:0')
we have a negative! tensor(-0.0751, device='cuda:0')
we have a negative! tensor(-0.0014, device='cuda:0')
we have a negative! tensor(-0.0409, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 3.4290e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 3.4290e-05.
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 3.4290e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1056, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 1.2009e-04.
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.2009e-05.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 1.2009e-06.
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 1.2009e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 2.4941e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0654, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 6.9459e-06.
32
32
32
8
32
32
32
32
29
Epoch 00020: reducing learning rate of group 0 to 6.9459e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have a negative! tensor(-0.0034, device='cuda:0')
32
we have a negative! tensor(-0.0229, device='cuda:0')
32
8
32
32
we have a negative! tensor(-0.0409, device='cuda:0')
32
32
29
we have a negative! tensor(-0.0196, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00042: reducing learning rate of group 0 to 6.1586e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0717, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0948, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0035, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0291, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0236, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0608, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0294, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0348, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0524, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0444, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0467, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0198, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0324, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0422, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0331, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0248, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0203, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0133, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0226, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0086, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0171, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0120, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0087, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0179, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0133, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0024, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-8.0559e-06, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0095, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0088, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0104, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0095, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0061, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0058, device='cuda:0')
32
32
8
32
32
32
we have a negative! tensor(-0.0031, device='cuda:0')
32
29
we have a negative! tensor(-0.0287, device='cuda:0')
we have a negative! tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0033, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0023, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0009, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0095, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0057, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0085, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0057, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0121, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0011, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0106, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0057, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0106, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0053, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0083, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0133, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0054, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0115, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0040, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0069, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0098, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0058, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0035, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0009, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0037, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0030, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0079, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0110, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0038, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0035, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0114, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0046, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0070, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0059, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-6.9495e-06, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0042, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0107, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0073, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0121, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0011, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0024, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0036, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0079, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0131, device='cuda:0')
we have a negative! tensor(-0.0508, device='cuda:0')
we have a negative! tensor(-0.0094, device='cuda:0')
we have a negative! tensor(-0.0008, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0136, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0027, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0053, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0009, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0042, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0023, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0072, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0034, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0132, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0025, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0058, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0063, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0057, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0076, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0012, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0029, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0008, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0015, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0012, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0010, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0043, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0038, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0053, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0326, device='cuda:0')
we have a negative! tensor(-0.0564, device='cuda:0')
we have a negative! tensor(-0.0314, device='cuda:0')
we have a negative! tensor(-0.0090, device='cuda:0')
we have a negative! tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0033, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0014, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0004, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0044, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0039, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0032, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0067, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0016, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0044, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0031, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0500, device='cuda:0')
we have a negative! tensor(-0.0726, device='cuda:0')
we have a negative! tensor(-0.0605, device='cuda:0')
we have a negative! tensor(-0.0376, device='cuda:0')
we have a negative! tensor(-0.0470, device='cuda:0')
we have a negative! tensor(-0.0556, device='cuda:0')
we have a negative! tensor(-0.0675, device='cuda:0')
we have a negative! tensor(-0.0548, device='cuda:0')
Epoch 00005: reducing learning rate of group 0 to 5.2421e-04.
32
32
32
we have a negative! tensor(-0.0633, device='cuda:0')
8
we have a negative! tensor(-0.0832, device='cuda:0')
32
32
32
we have a negative! tensor(-0.0707, device='cuda:0')
32
29
we have a negative! tensor(-0.0495, device='cuda:0')
we have a negative! tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0011, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0653, device='cuda:0')
we have a negative! tensor(-0.0879, device='cuda:0')
we have a negative! tensor(-0.0712, device='cuda:0')
we have a negative! tensor(-0.0494, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1092, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0478, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0820, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0630, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0743, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0647, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0256, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)
32
32
we have a negative! tensor(-0.0950, device='cuda:0')
32
we have a negative! tensor(-0.0313, device='cuda:0')
8
we have a negative! tensor(-0.1650, device='cuda:0')
32
we have a negative! tensor(-0.0577, device='cuda:0')
32
we have a negative! tensor(-0.1351, device='cuda:0')
32
we have a negative! tensor(-0.0353, device='cuda:0')
32
we have a negative! tensor(-0.0283, device='cuda:0')
29
we have a negative! tensor(-0.0933, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.0512e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0621, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 7.2871e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
8
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
29
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 7.2490e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.2406, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
Epoch 00004: reducing learning rate of group 0 to 9.7159e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0567, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0809, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0966, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0738, device='cuda:0', grad_fn=<SumBackward0>)
32
32
we have a negative! tensor(-0.0615, device='cuda:0')
32
8
we have a negative! tensor(-0.1436, device='cuda:0')
32
32
we have a negative! tensor(-0.0339, device='cuda:0')
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00047: reducing learning rate of group 0 to 2.5606e-07.
32
32
32
8
32
32
32
32
29
Epoch 00052: reducing learning rate of group 0 to 2.5606e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0325, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0719, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0617, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0345, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0570, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0568, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0323, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0775, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1565, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2289, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2168, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1889, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1385, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1569, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1298, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1306, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0937, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0703, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0767, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0602, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0802, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1031, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1096, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1295, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1047, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0900, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1229, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1096, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1034, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1019, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1168, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0313, device='cuda:0')
32
we have a negative! tensor(-0.0340, device='cuda:0')
32
we have a negative! tensor(-0.0396, device='cuda:0')
8
we have a negative! tensor(-0.0364, device='cuda:0')
32
we have a negative! tensor(-0.0322, device='cuda:0')
32
we have a negative! tensor(-0.0360, device='cuda:0')
32
we have a negative! tensor(-0.0377, device='cuda:0')
32
we have a negative! tensor(-0.0324, device='cuda:0')
29
we have a negative! tensor(-0.0335, device='cuda:0')
we have a negative! tensor(-0.0731, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0976, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1338, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1189, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0837, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0948, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0697, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1349, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1002, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0919, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0961, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0788, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1082, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0585, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0884, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0786, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1244, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0986, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1124, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1104, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0888, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0988, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0791, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0798, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0399, device='cuda:0')
we have a negative! tensor(-0.0390, device='cuda:0')
we have a negative! tensor(-0.0374, device='cuda:0')
we have a negative! tensor(-0.0357, device='cuda:0')
we have a negative! tensor(-0.0284, device='cuda:0')
we have a negative! tensor(-0.0394, device='cuda:0')
we have a negative! tensor(-0.0197, device='cuda:0')
we have a negative! tensor(-0.0970, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1044, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0854, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0957, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0465, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1038, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0622, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0748, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0749, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0695, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0556, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0301, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0659, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0602, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0210, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0028, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0197, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0318, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0078, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0185, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0574, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0551, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0932, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0444, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0650, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0780, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0635, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0879, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0431, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0305, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0665, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0627, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0373, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0539, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0871, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0732, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1039, device='cuda:0')
we have a negative! tensor(-0.1142, device='cuda:0')
we have a negative! tensor(-0.1026, device='cuda:0')
we have a negative! tensor(-0.1152, device='cuda:0')
we have a negative! tensor(-0.0937, device='cuda:0')
we have a negative! tensor(-0.1117, device='cuda:0')
we have a negative! tensor(-0.1101, device='cuda:0')
we have a negative! tensor(-0.1163, device='cuda:0')
we have a negative! tensor(-0.1040, device='cuda:0')
we have a negative! tensor(-0.0536, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0731, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0662, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0483, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0706, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0830, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0543, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0587, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0945, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0929, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0515, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0714, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0606, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0585, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0635, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0762, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0534, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0859, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0549, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0519, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0601, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0644, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0482, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0793, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0539, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0183, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0493, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0568, device='cuda:0')
we have a negative! tensor(-0.0614, device='cuda:0')
we have a negative! tensor(-0.0615, device='cuda:0')
we have a negative! tensor(-0.1197, device='cuda:0')
we have a negative! tensor(-0.0585, device='cuda:0')
we have a negative! tensor(-0.0925, device='cuda:0')
we have a negative! tensor(-0.0545, device='cuda:0')
we have a negative! tensor(-0.0742, device='cuda:0')
we have a negative! tensor(-0.0574, device='cuda:0')
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0709, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0241, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0485, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0166, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0524, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0529, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0516, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0761, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0629, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0626, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0619, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0506, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0661, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0492, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0493, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0635, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0575, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0568, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0470, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0333, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0214, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0428, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0413, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0502, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0461, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0343, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0331, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0365, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0412, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0292, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.2177, device='cuda:0')
32
we have a negative! tensor(-0.1601, device='cuda:0')
32
we have a negative! tensor(-0.0278, device='cuda:0')
8
we have a negative! tensor(-0.1212, device='cuda:0')
32
we have a negative! tensor(-0.2125, device='cuda:0')
32
we have a negative! tensor(-0.1534, device='cuda:0')
32
we have a negative! tensor(-0.0453, device='cuda:0')
32
we have a negative! tensor(-0.1488, device='cuda:0')
29
we have a negative! tensor(-0.1556, device='cuda:0')
Epoch 00006: reducing learning rate of group 0 to 1.4554e-04.
we have a negative! tensor(-0.0366, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0390, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0449, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0281, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0363, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0452, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0326, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0343, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0455, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0295, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0390, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0390, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0464, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0264, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0540, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0421, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0298, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0348, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0426, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0238, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0391, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0395, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0395, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0291, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0320, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0393, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0198, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0443, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0480, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0235, device='cuda:0')
we have a negative! tensor(-0.0298, device='cuda:0')
we have a negative! tensor(-0.0335, device='cuda:0')
we have a negative! tensor(-0.0373, device='cuda:0')
we have a negative! tensor(-0.0257, device='cuda:0')
we have a negative! tensor(-0.0500, device='cuda:0')
we have a negative! tensor(-0.0272, device='cuda:0')
we have a negative! tensor(-0.0373, device='cuda:0')
we have a negative! tensor(-0.0333, device='cuda:0')
we have a negative! tensor(-0.0418, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0306, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0426, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0449, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0409, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0290, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0438, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0315, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0366, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0402, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0355, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0263, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0513, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0504, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0361, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0492, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0380, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0354, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0405, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0498, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0344, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0305, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0289, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0336, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0405, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0427, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0455, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0424, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0440, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0423, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0374, device='cuda:0')
we have a negative! tensor(-0.0408, device='cuda:0')
we have a negative! tensor(-0.0378, device='cuda:0')
we have a negative! tensor(-0.0576, device='cuda:0')
we have a negative! tensor(-0.0059, device='cuda:0')
we have a negative! tensor(-0.0189, device='cuda:0')
we have a negative! tensor(-0.0300, device='cuda:0')
we have a negative! tensor(-0.0243, device='cuda:0')
we have a negative! tensor(-0.0161, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0313, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0286, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0293, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0428, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0416, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0414, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0487, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0265, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0395, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0550, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0459, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0559, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0430, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0484, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0406, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0365, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0393, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0319, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0017, device='cuda:0')
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0413, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0392, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0409, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0336, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0323, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0265, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0325, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0270, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0609, device='cuda:0')
we have a negative! tensor(-0.0687, device='cuda:0')
we have a negative! tensor(-0.1004, device='cuda:0')
we have a negative! tensor(-0.0586, device='cuda:0')
we have a negative! tensor(-0.0704, device='cuda:0')
we have a negative! tensor(-0.0671, device='cuda:0')
we have a negative! tensor(-0.0976, device='cuda:0')
we have a negative! tensor(-0.0585, device='cuda:0')
we have a negative! tensor(-0.0883, device='cuda:0')
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0288, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0275, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0329, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0258, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0254, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0289, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0280, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0329, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0253, device='cuda:0')
we have a negative! tensor(-0.0202, device='cuda:0')
we have a negative! tensor(-0.0197, device='cuda:0')
we have a negative! tensor(-0.0169, device='cuda:0')
we have a negative! tensor(-0.0376, device='cuda:0')
we have a negative! tensor(-0.0449, device='cuda:0')
we have a negative! tensor(-0.0261, device='cuda:0')
we have a negative! tensor(-0.0098, device='cuda:0')
we have a negative! tensor(-0.0430, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 4.7562e-07.
we have a negative! tensor(-0.0302, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0170, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0151, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0244, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0314, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0244, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0181, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0230, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0274, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0116, device='cuda:0')
we have a negative! tensor(-0.0074, device='cuda:0')
we have a negative! tensor(-0.0294, device='cuda:0')
we have a negative! tensor(-0.0449, device='cuda:0')
we have a negative! tensor(-0.0479, device='cuda:0')
we have a negative! tensor(-0.0328, device='cuda:0')
we have a negative! tensor(-0.0046, device='cuda:0')
we have a negative! tensor(-0.0200, device='cuda:0')
we have a negative! tensor(-0.0287, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0300, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0205, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0183, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0196, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0258, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0161, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0278, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0162, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0064, device='cuda:0')
32
we have a negative! tensor(-0.0072, device='cuda:0')
32
8
we have a negative! tensor(-0.0720, device='cuda:0')
32
we have a negative! tensor(-0.0369, device='cuda:0')
32
we have a negative! tensor(-0.0191, device='cuda:0')
32
32
29
we have a negative! tensor(-0.0130, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00007: reducing learning rate of group 0 to 1.5261e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 4.3487e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 4.3487e-06.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 4.3487e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0075, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00010: reducing learning rate of group 0 to 1.7236e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 1.7236e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.7236e-06.
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 1.7236e-07.
Epoch 00034: reducing learning rate of group 0 to 1.7236e-08.
32
32
32
8
32
32
32
32
29
Epoch 00037: reducing learning rate of group 0 to 1.7236e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0426, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00023: reducing learning rate of group 0 to 2.7446e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1101, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00007: reducing learning rate of group 0 to 2.6951e-05.
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 2.6951e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have a negative! tensor(-0.0561, device='cuda:0')
32
we have a negative! tensor(-0.0718, device='cuda:0')
32
we have a negative! tensor(-0.0581, device='cuda:0')
8
we have a negative! tensor(-0.0779, device='cuda:0')
32
we have a negative! tensor(-0.0572, device='cuda:0')
32
we have a negative! tensor(-0.0739, device='cuda:0')
32
we have a negative! tensor(-0.0583, device='cuda:0')
32
we have a negative! tensor(-0.0685, device='cuda:0')
29
we have a negative! tensor(-0.0580, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 2.8953e-04.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0397, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 7.2571e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0005, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00029: reducing learning rate of group 0 to 9.8892e-06.
32
32
32
8
32
32
32
32
29
Epoch 00035: reducing learning rate of group 0 to 9.8892e-07.
32
32
32
8
32
32
32
32
29
Epoch 00038: reducing learning rate of group 0 to 9.8892e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0538, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 7.4557e-04.
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 7.4557e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0026, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1391, device='cuda:0')
32
we have a negative! tensor(-0.1772, device='cuda:0')
32
we have a negative! tensor(-0.1272, device='cuda:0')
8
we have a negative! tensor(-0.1618, device='cuda:0')
32
we have a negative! tensor(-0.0768, device='cuda:0')
32
we have a negative! tensor(-0.1681, device='cuda:0')
32
we have a negative! tensor(-0.1633, device='cuda:0')
32
we have a negative! tensor(-0.1413, device='cuda:0')
29
we have a negative! tensor(-0.1428, device='cuda:0')
we have a negative! tensor(-0.0110, device='cuda:0')
we have a negative! tensor(-0.0125, device='cuda:0')
we have a negative! tensor(-0.1422, device='cuda:0')
we have a negative! tensor(-0.0657, device='cuda:0')
we have a negative! tensor(-0.0148, device='cuda:0')
we have a negative! tensor(-0.0482, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.8901e-05.
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 1.8901e-06.
Epoch 00029: reducing learning rate of group 0 to 1.8901e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have a negative! tensor(-0.0920, device='cuda:0')
32
we have a negative! tensor(-0.0680, device='cuda:0')
32
we have a negative! tensor(-0.0486, device='cuda:0')
8
we have a negative! tensor(-0.1054, device='cuda:0')
32
we have a negative! tensor(-0.0923, device='cuda:0')
32
we have a negative! tensor(-0.0924, device='cuda:0')
32
we have a negative! tensor(-0.0506, device='cuda:0')
32
we have a negative! tensor(-0.0703, device='cuda:0')
29
we have a negative! tensor(-0.0701, device='cuda:0')
we have a negative! tensor(-0.0511, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0199, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0084, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0087, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0463, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0133, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1533, device='cuda:0')
we have a negative! tensor(-0.1211, device='cuda:0')
we have a negative! tensor(-0.0691, device='cuda:0')
we have a negative! tensor(-0.1189, device='cuda:0')
we have a negative! tensor(-0.1078, device='cuda:0')
we have a negative! tensor(-0.1520, device='cuda:0')
we have a negative! tensor(-0.1453, device='cuda:0')
we have a negative! tensor(-0.1381, device='cuda:0')
we have a negative! tensor(-0.1860, device='cuda:0')
we have a negative! tensor(-0.0640, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0378, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0288, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0100, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0421, device='cuda:0')
we have a negative! tensor(-0.0234, device='cuda:0')
we have a negative! tensor(-0.0545, device='cuda:0')
we have a negative! tensor(-0.0883, device='cuda:0')
we have a negative! tensor(-0.0280, device='cuda:0')
we have a negative! tensor(-0.0728, device='cuda:0')
we have a negative! tensor(-0.0215, device='cuda:0')
we have a negative! tensor(-0.1036, device='cuda:0')
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0533, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0546, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0180, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0046, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0786, device='cuda:0')
we have a negative! tensor(-0.0040, device='cuda:0')
we have a negative! tensor(-0.0223, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 2.1884e-06.
we have a negative! tensor(-0.0015, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0097, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0149, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0082, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0405, device='cuda:0')
we have a negative! tensor(-0.0586, device='cuda:0')
we have a negative! tensor(-0.0692, device='cuda:0')
we have a negative! tensor(-0.0111, device='cuda:0')
we have a negative! tensor(-0.0313, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0156, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0093, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0018, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0540, device='cuda:0')
32
32
we have a negative! tensor(-0.0357, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0992, device='cuda:0')
32
we have a negative! tensor(-0.0222, device='cuda:0')
29
we have a negative! tensor(-0.0272, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0849, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 2.8231e-05.
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 2.8231e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0333, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0578, device='cuda:0')
32
we have a negative! tensor(-0.0162, device='cuda:0')
32
8
32
32
32
we have a negative! tensor(-0.0026, device='cuda:0')
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00030: reducing learning rate of group 0 to 2.1964e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 7.0486e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 7.0486e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0018, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0299, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0430, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0549, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0040, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0045, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0081, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0046, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0116, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0205, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0111, device='cuda:0')
we have a negative! tensor(-0.0365, device='cuda:0')
we have a negative! tensor(-0.0326, device='cuda:0')
we have a negative! tensor(-0.0154, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0084, device='cuda:0')
we have a negative! tensor(-0.0352, device='cuda:0')
we have a negative! tensor(-0.0317, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 3.0772e-05.
we have a negative! tensor(-0.0092, device='cuda:0')
we have a negative! tensor(-0.0360, device='cuda:0')
we have a negative! tensor(-0.0325, device='cuda:0')
we have a negative! tensor(-0.0074, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0023, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0082, device='cuda:0')
32
32
we have a negative! tensor(-0.0357, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0321, device='cuda:0')
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0760, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2568, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2801, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0120, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2590, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2437, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0115, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1762, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1795, device='cuda:0', grad_fn=<SumBackward0>)
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
8
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
29
we have constant predictions!
we have a negative! tensor(-0.1446, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1485, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1217, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1158, device='cuda:0', grad_fn=<SumBackward0>)
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0017, device='cuda:0')
we have a negative! tensor(-0.0088, device='cuda:0')
we have a negative! tensor(-0.0023, device='cuda:0')
Epoch 00008: reducing learning rate of group 0 to 4.9595e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0023, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0151, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.2404, device='cuda:0')
32
we have a negative! tensor(-0.2682, device='cuda:0')
32
we have a negative! tensor(-0.1773, device='cuda:0')
8
we have a negative! tensor(-0.2380, device='cuda:0')
32
we have a negative! tensor(-0.1628, device='cuda:0')
32
we have a negative! tensor(-0.2344, device='cuda:0')
32
we have a negative! tensor(-0.2161, device='cuda:0')
32
we have a negative! tensor(-0.2238, device='cuda:0')
29
we have a negative! tensor(-0.2212, device='cuda:0')
we have a negative! tensor(-0.1285, device='cuda:0')
we have a negative! tensor(-0.0779, device='cuda:0')
we have a negative! tensor(-0.0463, device='cuda:0')
we have a negative! tensor(-0.0515, device='cuda:0')
we have a negative! tensor(-0.0210, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.2820e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0497, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1581, device='cuda:0')
32
we have a negative! tensor(-0.2429, device='cuda:0')
32
we have a negative! tensor(-0.1347, device='cuda:0')
8
we have a negative! tensor(-0.2691, device='cuda:0')
32
we have a negative! tensor(-0.1362, device='cuda:0')
32
we have a negative! tensor(-0.2342, device='cuda:0')
32
we have a negative! tensor(-0.1437, device='cuda:0')
32
we have a negative! tensor(-0.2166, device='cuda:0')
29
we have a negative! tensor(-0.1692, device='cuda:0')
we have a negative! tensor(-0.0914, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1586, device='cuda:0')
we have a negative! tensor(-0.2223, device='cuda:0')
we have a negative! tensor(-0.1380, device='cuda:0')
we have a negative! tensor(-0.2383, device='cuda:0')
we have a negative! tensor(-0.1325, device='cuda:0')
we have a negative! tensor(-0.2112, device='cuda:0')
we have a negative! tensor(-0.1465, device='cuda:0')
we have a negative! tensor(-0.2011, device='cuda:0')
we have a negative! tensor(-0.1574, device='cuda:0')
we have a negative! tensor(-0.0867, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1446, device='cuda:0')
we have a negative! tensor(-0.2307, device='cuda:0')
we have a negative! tensor(-0.0956, device='cuda:0')
we have a negative! tensor(-0.2549, device='cuda:0')
we have a negative! tensor(-0.1058, device='cuda:0')
we have a negative! tensor(-0.2101, device='cuda:0')
we have a negative! tensor(-0.1160, device='cuda:0')
we have a negative! tensor(-0.2017, device='cuda:0')
we have a negative! tensor(-0.1495, device='cuda:0')
we have a negative! tensor(-0.0293, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0156, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0025, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1845, device='cuda:0')
we have a negative! tensor(-0.2895, device='cuda:0')
we have a negative! tensor(-0.1533, device='cuda:0')
we have a negative! tensor(-0.3211, device='cuda:0')
we have a negative! tensor(-0.1475, device='cuda:0')
we have a negative! tensor(-0.2741, device='cuda:0')
we have a negative! tensor(-0.1738, device='cuda:0')
we have a negative! tensor(-0.2512, device='cuda:0')
we have a negative! tensor(-0.2003, device='cuda:0')
we have a negative! tensor(-0.1647, device='cuda:0')
we have a negative! tensor(-0.2793, device='cuda:0')
we have a negative! tensor(-0.1154, device='cuda:0')
we have a negative! tensor(-0.3202, device='cuda:0')
we have a negative! tensor(-0.1197, device='cuda:0')
we have a negative! tensor(-0.2552, device='cuda:0')
we have a negative! tensor(-0.1505, device='cuda:0')
we have a negative! tensor(-0.2332, device='cuda:0')
we have a negative! tensor(-0.1830, device='cuda:0')
we have a negative! tensor(-0.0072, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1892, device='cuda:0')
32
we have a negative! tensor(-0.3196, device='cuda:0')
32
we have a negative! tensor(-0.1422, device='cuda:0')
8
we have a negative! tensor(-0.3758, device='cuda:0')
32
we have a negative! tensor(-0.1463, device='cuda:0')
32
we have a negative! tensor(-0.2979, device='cuda:0')
32
we have a negative! tensor(-0.1835, device='cuda:0')
32
we have a negative! tensor(-0.2695, device='cuda:0')
29
we have a negative! tensor(-0.2231, device='cuda:0')
we have a negative! tensor(-0.0064, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1049, device='cuda:0')
we have a negative! tensor(-0.2163, device='cuda:0')
we have a negative! tensor(-0.0414, device='cuda:0')
we have a negative! tensor(-0.2575, device='cuda:0')
we have a negative! tensor(-0.0644, device='cuda:0')
we have a negative! tensor(-0.1907, device='cuda:0')
we have a negative! tensor(-0.0887, device='cuda:0')
we have a negative! tensor(-0.1701, device='cuda:0')
we have a negative! tensor(-0.1300, device='cuda:0')
we have a negative! tensor(-0.0161, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0071, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0015, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0794, device='cuda:0')
we have a negative! tensor(-0.1635, device='cuda:0')
we have a negative! tensor(-0.0169, device='cuda:0')
we have a negative! tensor(-0.1841, device='cuda:0')
we have a negative! tensor(-0.0403, device='cuda:0')
we have a negative! tensor(-0.1372, device='cuda:0')
we have a negative! tensor(-0.0616, device='cuda:0')
we have a negative! tensor(-0.1275, device='cuda:0')
we have a negative! tensor(-0.0904, device='cuda:0')
we have a negative! tensor(-0.0030, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0741, device='cuda:0')
we have a negative! tensor(-0.1335, device='cuda:0')
we have a negative! tensor(-0.0149, device='cuda:0')
we have a negative! tensor(-0.1335, device='cuda:0')
we have a negative! tensor(-0.0367, device='cuda:0')
we have a negative! tensor(-0.1075, device='cuda:0')
we have a negative! tensor(-0.0532, device='cuda:0')
we have a negative! tensor(-0.1079, device='cuda:0')
we have a negative! tensor(-0.0677, device='cuda:0')
Epoch 00009: reducing learning rate of group 0 to 8.0525e-05.
we have a negative! tensor(-0.0084, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0065, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0124, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0550, device='cuda:0')
we have a negative! tensor(-0.1015, device='cuda:0')
we have a negative! tensor(-0.0115, device='cuda:0')
we have a negative! tensor(-0.0621, device='cuda:0')
we have a negative! tensor(-0.0133, device='cuda:0')
we have a negative! tensor(-0.0737, device='cuda:0')
we have a negative! tensor(-0.0448, device='cuda:0')
we have a negative! tensor(-0.0709, device='cuda:0')
we have a negative! tensor(-0.0318, device='cuda:0')
we have a negative! tensor(-0.0065, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0157, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0014, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1174, device='cuda:0')
32
we have a negative! tensor(-0.1097, device='cuda:0')
32
we have a negative! tensor(-0.1283, device='cuda:0')
8
we have a negative! tensor(-0.0897, device='cuda:0')
32
we have a negative! tensor(-0.1069, device='cuda:0')
32
we have a negative! tensor(-0.1086, device='cuda:0')
32
we have a negative! tensor(-0.1414, device='cuda:0')
32
we have a negative! tensor(-0.1039, device='cuda:0')
29
we have a negative! tensor(-0.1106, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0375, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1238, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0084, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0103, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0555, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0021, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0613, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0303, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1006, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0379, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0403, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0120, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0940, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0297, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0878, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0533, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0740, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1206, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0554, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0438, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0338, device='cuda:0')
we have a negative! tensor(-0.0722, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1010, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0075, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0969, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0418, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0967, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0544, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0541, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0669, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0781, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1400, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0805, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0688, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0602, device='cuda:0')
we have a negative! tensor(-0.2105, device='cuda:0')
we have a negative! tensor(-0.0621, device='cuda:0')
we have a negative! tensor(-0.0305, device='cuda:0')
we have a negative! tensor(-0.0473, device='cuda:0')
we have a negative! tensor(-0.0050, device='cuda:0')
we have a negative! tensor(-0.0784, device='cuda:0')
we have a negative! tensor(-0.1070, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0973, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0301, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1505, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1283, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0188, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0312, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0671, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0557, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0875, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0342, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1277, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0657, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0668, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1194, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0847, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0847, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0836, device='cuda:0')
we have a negative! tensor(-0.1323, device='cuda:0')
we have a negative! tensor(-0.1085, device='cuda:0')
we have a negative! tensor(-0.1220, device='cuda:0')
we have a negative! tensor(-0.0270, device='cuda:0')
we have a negative! tensor(-0.0733, device='cuda:0')
we have a negative! tensor(-0.0879, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 1.4234e-07.
we have a negative! tensor(-0.0910, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0847, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1258, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0587, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0081, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0309, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0768, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1276, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0236, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1139, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1031, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0263, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1184, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0766, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1764, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1026, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0177, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0483, device='cuda:0')
we have a negative! tensor(-0.1745, device='cuda:0')
we have a negative! tensor(-0.1609, device='cuda:0')
we have a negative! tensor(-0.0837, device='cuda:0')
we have a negative! tensor(-0.0602, device='cuda:0')
we have a negative! tensor(-0.1278, device='cuda:0')
we have a negative! tensor(-0.0823, device='cuda:0')
we have a negative! tensor(-0.1089, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0186, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0126, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0180, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0545, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0858, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0093, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0981, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0648, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1083, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0319, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0073, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0709, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0274, device='cuda:0', grad_fn=<SumBackward0>)
32
32
we have a negative! tensor(-0.0615, device='cuda:0')
32
8
we have a negative! tensor(-0.1484, device='cuda:0')
32
we have a negative! tensor(-0.1491, device='cuda:0')
32
we have a negative! tensor(-0.0777, device='cuda:0')
32
we have a negative! tensor(-0.0667, device='cuda:0')
32
we have a negative! tensor(-0.1058, device='cuda:0')
29
we have a negative! tensor(-0.0836, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0056, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
we have a negative! tensor(-0.1751, device='cuda:0')
32
32
32
32
29
we have a negative! tensor(-0.2843, device='cuda:0')
we have a negative! tensor(-0.0524, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00073: reducing learning rate of group 0 to 2.5381e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1058, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0526, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0772, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2889, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2912, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0254, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1083, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1434, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2332, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1780, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2106, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1913, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0763, device='cuda:0')
32
we have a negative! tensor(-0.0467, device='cuda:0')
32
we have a negative! tensor(-0.0765, device='cuda:0')
8
we have a negative! tensor(-0.0228, device='cuda:0')
32
we have a negative! tensor(-0.0592, device='cuda:0')
32
we have a negative! tensor(-0.0441, device='cuda:0')
32
we have a negative! tensor(-0.0677, device='cuda:0')
32
we have a negative! tensor(-0.0499, device='cuda:0')
29
we have a negative! tensor(-0.0451, device='cuda:0')
we have a negative! tensor(-0.2155, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0994, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0339, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0407, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1173, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1243, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0986, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0774, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1286, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1153, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1323, device='cuda:0', grad_fn=<SumBackward0>)
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have a negative! tensor(-0.1237, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1165, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0845, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0465, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0316, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0302, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0707, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0634, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0692, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0878, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0889, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0571, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0323, device='cuda:0')
we have a negative! tensor(-0.0183, device='cuda:0')
we have a negative! tensor(-0.0291, device='cuda:0')
we have a negative! tensor(-0.0099, device='cuda:0')
we have a negative! tensor(-0.0240, device='cuda:0')
we have a negative! tensor(-0.0168, device='cuda:0')
we have a negative! tensor(-0.0268, device='cuda:0')
we have a negative! tensor(-0.0205, device='cuda:0')
we have a negative! tensor(-0.0191, device='cuda:0')
we have a negative! tensor(-0.0611, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0697, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0467, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0300, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0557, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0585, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0634, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0673, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0511, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0627, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0659, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0523, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0674, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0328, device='cuda:0')
we have a negative! tensor(-0.0187, device='cuda:0')
we have a negative! tensor(-0.0307, device='cuda:0')
we have a negative! tensor(-0.0101, device='cuda:0')
we have a negative! tensor(-0.0246, device='cuda:0')
we have a negative! tensor(-0.0175, device='cuda:0')
we have a negative! tensor(-0.0280, device='cuda:0')
we have a negative! tensor(-0.0211, device='cuda:0')
we have a negative! tensor(-0.0197, device='cuda:0')
we have a negative! tensor(-0.0798, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0636, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0709, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0823, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0733, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0888, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0866, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0846, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0965, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0879, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0979, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0864, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0860, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0819, device='cuda:0')
we have a negative! tensor(-0.0273, device='cuda:0')
we have a negative! tensor(-0.0817, device='cuda:0')
we have a negative! tensor(-0.0473, device='cuda:0')
we have a negative! tensor(-0.0782, device='cuda:0')
we have a negative! tensor(-0.0442, device='cuda:0')
we have a negative! tensor(-0.0384, device='cuda:0')
we have a negative! tensor(-0.1010, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0627, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0614, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0461, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0493, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0579, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0465, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0545, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0442, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0429, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0395, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0453, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0377, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0394, device='cuda:0')
32
we have a negative! tensor(-0.0077, device='cuda:0')
32
we have a negative! tensor(-0.0592, device='cuda:0')
8
32
we have a negative! tensor(-0.0329, device='cuda:0')
32
we have a negative! tensor(-0.0527, device='cuda:0')
32
we have a negative! tensor(-0.0624, device='cuda:0')
32
we have a negative! tensor(-0.0127, device='cuda:0')
29
we have a negative! tensor(-0.0324, device='cuda:0')
we have a negative! tensor(-0.0400, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0548, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0593, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0773, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0738, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0617, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0585, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0677, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0646, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0851, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0735, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0545, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0615, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0528, device='cuda:0')
we have a negative! tensor(-0.0184, device='cuda:0')
we have a negative! tensor(-0.0569, device='cuda:0')
we have a negative! tensor(-0.0358, device='cuda:0')
we have a negative! tensor(-0.0341, device='cuda:0')
we have a negative! tensor(-0.0682, device='cuda:0')
we have a negative! tensor(-0.0605, device='cuda:0')
we have a negative! tensor(-0.0451, device='cuda:0')
we have a negative! tensor(-0.0307, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0607, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0601, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0658, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0373, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0618, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0499, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0544, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0598, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0424, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0615, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0815, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0676, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0636, device='cuda:0')
we have a negative! tensor(-0.0408, device='cuda:0')
we have a negative! tensor(-0.0859, device='cuda:0')
we have a negative! tensor(-0.0231, device='cuda:0')
we have a negative! tensor(-0.0586, device='cuda:0')
we have a negative! tensor(-0.0570, device='cuda:0')
we have a negative! tensor(-0.0789, device='cuda:0')
we have a negative! tensor(-0.0668, device='cuda:0')
we have a negative! tensor(-0.0610, device='cuda:0')
Epoch 00008: reducing learning rate of group 0 to 3.2241e-04.
we have a negative! tensor(-0.0617, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0588, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0643, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0505, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0608, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0756, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0496, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0790, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0543, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0758, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0782, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0788, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0642, device='cuda:0')
we have a negative! tensor(-0.0498, device='cuda:0')
we have a negative! tensor(-0.0721, device='cuda:0')
we have a negative! tensor(-0.0289, device='cuda:0')
we have a negative! tensor(-0.0655, device='cuda:0')
we have a negative! tensor(-0.0878, device='cuda:0')
we have a negative! tensor(-0.0777, device='cuda:0')
we have a negative! tensor(-0.0473, device='cuda:0')
we have a negative! tensor(-0.0667, device='cuda:0')
we have a negative! tensor(-0.0522, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0480, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0450, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0760, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0621, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0540, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0405, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0689, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0544, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0644, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0604, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0802, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0528, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0649, device='cuda:0')
we have a negative! tensor(-0.0521, device='cuda:0')
we have a negative! tensor(-0.0731, device='cuda:0')
we have a negative! tensor(-0.0325, device='cuda:0')
we have a negative! tensor(-0.0737, device='cuda:0')
we have a negative! tensor(-0.0943, device='cuda:0')
we have a negative! tensor(-0.0744, device='cuda:0')
we have a negative! tensor(-0.0498, device='cuda:0')
we have a negative! tensor(-0.0733, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1108, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0807, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0964, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0728, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0950, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0614, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0997, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0624, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0859, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0560, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0624, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0831, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0852, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0368, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0514, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0515, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0275, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0326, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0408, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0097, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0153, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1728, device='cuda:0')
we have a negative! tensor(-0.3124, device='cuda:0')
we have a negative! tensor(-0.2022, device='cuda:0')
we have a negative! tensor(-0.4052, device='cuda:0')
we have a negative! tensor(-0.1811, device='cuda:0')
we have a negative! tensor(-0.3244, device='cuda:0')
we have a negative! tensor(-0.2141, device='cuda:0')
we have a negative! tensor(-0.2890, device='cuda:0')
we have a negative! tensor(-0.2461, device='cuda:0')
we have a negative! tensor(-0.0200, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0178, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0021, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0004, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1172, device='cuda:0')
we have a negative! tensor(-0.1810, device='cuda:0')
we have a negative! tensor(-0.1482, device='cuda:0')
we have a negative! tensor(-0.2526, device='cuda:0')
we have a negative! tensor(-0.1455, device='cuda:0')
we have a negative! tensor(-0.1756, device='cuda:0')
we have a negative! tensor(-0.1633, device='cuda:0')
we have a negative! tensor(-0.1850, device='cuda:0')
we have a negative! tensor(-0.1501, device='cuda:0')
we have a negative! tensor(-0.0791, device='cuda:0')
we have a negative! tensor(-0.1047, device='cuda:0')
we have a negative! tensor(-0.0723, device='cuda:0')
we have a negative! tensor(-0.1324, device='cuda:0')
we have a negative! tensor(-0.0542, device='cuda:0')
we have a negative! tensor(-0.1165, device='cuda:0')
we have a negative! tensor(-0.0798, device='cuda:0')
we have a negative! tensor(-0.1057, device='cuda:0')
we have a negative! tensor(-0.0642, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 3.8085e-07.
we have a negative! tensor(-0.0820, device='cuda:0')
32
32
32
8
we have a negative! tensor(-0.0320, device='cuda:0')
32
32
32
32
we have a negative! tensor(-0.0645, device='cuda:0')
29
we have a negative! tensor(-0.0575, device='cuda:0')
we have a negative! tensor(-0.0040, device='cuda:0')
Epoch 00009: reducing learning rate of group 0 to 3.8085e-08.
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0002, device='cuda:0')
Epoch 00015: reducing learning rate of group 0 to 3.8085e-09.
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0006, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0123, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 4.5084e-04.
32
32
32
8
32
32
32
32
29
Epoch 00024: reducing learning rate of group 0 to 4.5084e-05.
32
32
32
8
32
32
32
32
29
Epoch 00030: reducing learning rate of group 0 to 4.5084e-06.
32
32
32
8
32
32
32
32
29
Epoch 00033: reducing learning rate of group 0 to 4.5084e-07.
32
32
32
8
32
32
32
32
29
Epoch 00036: reducing learning rate of group 0 to 4.5084e-08.
32
32
32
8
32
32
32
32
29
Epoch 00041: reducing learning rate of group 0 to 4.5084e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0773, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0647, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0310, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1583, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1847, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2601, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0670, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1737, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0318, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0725, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0987, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1437, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0609, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0636, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1575, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0238, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0463, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1927, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1112, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.1270, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1115, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0959, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1075, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0025, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0117, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1053, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0018, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0093, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-3.8131e-06, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0207, device='cuda:0')
we have a negative! tensor(-0.0189, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0358, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0231, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0054, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-8.0673e-05, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0157, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0057, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0161, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0370, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0805, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0560, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0016, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0051, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0222, device='cuda:0')
we have a negative! tensor(-0.0568, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0098, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0186, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0095, device='cuda:0')
we have a negative! tensor(-0.0020, device='cuda:0')
we have a negative! tensor(-0.0042, device='cuda:0')
we have a negative! tensor(-0.0083, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 9.6123e-07.
we have a negative! tensor(-0.0049, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0476, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0146, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0114, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0086, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0224, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0108, device='cuda:0')
we have a negative! tensor(-0.0195, device='cuda:0')
we have a negative! tensor(-0.0409, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0447, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0290, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0080, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0077, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0263, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0291, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0016, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0305, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0273, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0113, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
we have a negative! tensor(-0.0183, device='cuda:0')
32
29
we have a negative! tensor(-0.0045, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1150, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0759, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0751, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0636, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0463, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0415, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0116, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
we have a negative! tensor(-0.0035, device='cuda:0')
32
32
32
32
29
we have a negative! tensor(-0.0398, device='cuda:0')
we have a negative! tensor(-0.0282, device='cuda:0')
we have a negative! tensor(-0.0937, device='cuda:0')
we have a negative! tensor(-0.0358, device='cuda:0')
we have a negative! tensor(-0.0208, device='cuda:0')
we have a negative! tensor(-0.0106, device='cuda:0')
we have a negative! tensor(-0.0493, device='cuda:0')
we have a negative! tensor(-0.1601, device='cuda:0')
we have a negative! tensor(-0.0578, device='cuda:0')
we have a negative! tensor(-0.0022, device='cuda:0')
we have a negative! tensor(-0.0139, device='cuda:0')
we have a negative! tensor(-0.0114, device='cuda:0')
we have a negative! tensor(-0.1091, device='cuda:0')
we have a negative! tensor(-0.1563, device='cuda:0')
we have a negative! tensor(-0.0170, device='cuda:0')
we have a negative! tensor(-0.1101, device='cuda:0')
we have a negative! tensor(-0.0734, device='cuda:0')
we have a negative! tensor(-0.0924, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 1.2312e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00062: reducing learning rate of group 0 to 1.2312e-07.
32
32
32
8
32
32
32
32
29
Epoch 00066: reducing learning rate of group 0 to 1.2312e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00010: reducing learning rate of group 0 to 3.1293e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0370, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 1.7779e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0967, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 3.2794e-05.
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 3.2794e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0394, device='cuda:0')
we have a negative! tensor(-0.0662, device='cuda:0')
we have a negative! tensor(-0.0212, device='cuda:0')
we have a negative! tensor(-0.2541, device='cuda:0')
we have a negative! tensor(-0.0378, device='cuda:0')
we have a negative! tensor(-0.0857, device='cuda:0')
we have a negative! tensor(-0.0730, device='cuda:0')
we have a negative! tensor(-0.0783, device='cuda:0')
we have a negative! tensor(-0.1500, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 4.1521e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 4.1521e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0539, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00006: reducing learning rate of group 0 to 1.4221e-05.
32
32
32
8
32
32
32
32
29
Epoch 00014: reducing learning rate of group 0 to 1.4221e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 1.2493e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0245, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0898, device='cuda:0', grad_fn=<SumBackward0>)
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
8
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
32
we have constant predictions!
29
we have constant predictions!
we have a negative! tensor(-0.0241, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0373, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0362, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0328, device='cuda:0', grad_fn=<SumBackward0>)
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have constant predictions!
we have a negative! tensor(-0.0251, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0167, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0067, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0009, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0452, device='cuda:0')
we have a negative! tensor(-0.0256, device='cuda:0')
we have a negative! tensor(-0.0492, device='cuda:0')
we have a negative! tensor(-0.0122, device='cuda:0')
we have a negative! tensor(-0.0352, device='cuda:0')
we have a negative! tensor(-0.0228, device='cuda:0')
we have a negative! tensor(-0.0490, device='cuda:0')
we have a negative! tensor(-0.0314, device='cuda:0')
we have a negative! tensor(-0.0295, device='cuda:0')
we have a negative! tensor(-0.0237, device='cuda:0')
we have a negative! tensor(-0.0142, device='cuda:0')
we have a negative! tensor(-0.0169, device='cuda:0')
we have a negative! tensor(-0.1670, device='cuda:0')
we have a negative! tensor(-0.1068, device='cuda:0')
we have a negative! tensor(-0.2242, device='cuda:0')
we have a negative! tensor(-0.0792, device='cuda:0')
we have a negative! tensor(-0.1385, device='cuda:0')
we have a negative! tensor(-0.1188, device='cuda:0')
we have a negative! tensor(-0.2260, device='cuda:0')
we have a negative! tensor(-0.1266, device='cuda:0')
we have a negative! tensor(-0.1588, device='cuda:0')
we have a negative! tensor(-0.0029, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0008, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0094, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0043, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0013, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.1191, device='cuda:0')
32
we have a negative! tensor(-0.0297, device='cuda:0')
32
we have a negative! tensor(-0.0535, device='cuda:0')
8
32
we have a negative! tensor(-0.1326, device='cuda:0')
32
we have a negative! tensor(-0.0322, device='cuda:0')
32
we have a negative! tensor(-0.0466, device='cuda:0')
32
we have a negative! tensor(-0.0498, device='cuda:0')
29
we have a negative! tensor(-0.0670, device='cuda:0')
we have a negative! tensor(-0.0105, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0085, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0064, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0100, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0088, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0091, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0123, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0066, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0025, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0732, device='cuda:0')
we have a negative! tensor(-0.0140, device='cuda:0')
we have a negative! tensor(-0.0373, device='cuda:0')
we have a negative! tensor(-0.0675, device='cuda:0')
we have a negative! tensor(-0.0138, device='cuda:0')
we have a negative! tensor(-0.0393, device='cuda:0')
we have a negative! tensor(-0.0113, device='cuda:0')
we have a negative! tensor(-0.0450, device='cuda:0')
Epoch 00007: reducing learning rate of group 0 to 5.0631e-04.
we have a negative! tensor(-0.0092, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0123, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0134, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0117, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0115, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0121, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0056, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0010, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0078, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0284, device='cuda:0')
we have a negative! tensor(-0.0045, device='cuda:0')
we have a negative! tensor(-0.0272, device='cuda:0')
we have a negative! tensor(-0.0226, device='cuda:0')
we have a negative! tensor(-0.0018, device='cuda:0')
we have a negative! tensor(-0.0281, device='cuda:0')
we have a negative! tensor(-0.0015, device='cuda:0')
we have a negative! tensor(-0.0143, device='cuda:0')
we have a negative! tensor(-0.0049, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0079, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0140, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0122, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0032, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0084, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0095, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0061, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0116, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0072, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0182, device='cuda:0')
we have a negative! tensor(-0.0241, device='cuda:0')
we have a negative! tensor(-0.0119, device='cuda:0')
we have a negative! tensor(-0.0247, device='cuda:0')
we have a negative! tensor(-0.0097, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0509, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0085, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0197, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0006, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0092, device='cuda:0', grad_fn=<SumBackward0>)
Epoch 00004: reducing learning rate of group 0 to 3.2669e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1134, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 7.4810e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 7.4810e-05.
32
32
32
8
32
32
32
32
29
Epoch 00034: reducing learning rate of group 0 to 7.4810e-06.
32
32
32
8
32
32
32
32
29
Epoch 00037: reducing learning rate of group 0 to 7.4810e-07.
Epoch 00040: reducing learning rate of group 0 to 7.4810e-08.
32
32
32
8
32
32
32
32
29
Epoch 00044: reducing learning rate of group 0 to 7.4810e-09.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00073: reducing learning rate of group 0 to 9.8282e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
Epoch 00005: reducing learning rate of group 0 to 1.5170e-04.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.2406, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
Epoch 00005: reducing learning rate of group 0 to 7.8910e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 2.5973e-05.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 2.5973e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 7.2939e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have a negative! tensor(-0.0005, device='cuda:0')
32
we have a negative! tensor(-0.1409, device='cuda:0')
32
we have a negative! tensor(-0.1168, device='cuda:0')
8
we have a negative! tensor(-0.0829, device='cuda:0')
32
32
we have a negative! tensor(-0.0369, device='cuda:0')
32
we have a negative! tensor(-0.0467, device='cuda:0')
32
we have a negative! tensor(-0.0050, device='cuda:0')
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00046: reducing learning rate of group 0 to 4.5606e-07.
32
32
32
8
32
32
32
32
29
Epoch 00053: reducing learning rate of group 0 to 4.5606e-08.
32
32
32
8
32
32
32
32
29
Epoch 00056: reducing learning rate of group 0 to 4.5606e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0300, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0506, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0362, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0415, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0070, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0065, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0352, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0422, device='cuda:0')
32
we have a negative! tensor(-0.0532, device='cuda:0')
32
we have a negative! tensor(-0.0486, device='cuda:0')
8
we have a negative! tensor(-0.0598, device='cuda:0')
32
we have a negative! tensor(-0.0423, device='cuda:0')
32
we have a negative! tensor(-0.0545, device='cuda:0')
32
we have a negative! tensor(-0.0492, device='cuda:0')
32
we have a negative! tensor(-0.0491, device='cuda:0')
29
we have a negative! tensor(-0.0491, device='cuda:0')
we have a negative! tensor(-0.0812, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0756, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1113, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0220, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1067, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1069, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0928, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0122, device='cuda:0')
we have a negative! tensor(-0.1376, device='cuda:0')
we have a negative! tensor(-0.2070, device='cuda:0')
we have a negative! tensor(-0.0202, device='cuda:0')
we have a negative! tensor(-0.1286, device='cuda:0')
we have a negative! tensor(-0.0995, device='cuda:0')
we have a negative! tensor(-0.0605, device='cuda:0')
we have a negative! tensor(-0.0844, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0958, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0801, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0770, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1364, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0825, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0657, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0571, device='cuda:0')
we have a negative! tensor(-0.0649, device='cuda:0')
we have a negative! tensor(-0.0649, device='cuda:0')
we have a negative! tensor(-0.0702, device='cuda:0')
we have a negative! tensor(-0.0602, device='cuda:0')
we have a negative! tensor(-0.0674, device='cuda:0')
we have a negative! tensor(-0.0623, device='cuda:0')
we have a negative! tensor(-0.0632, device='cuda:0')
we have a negative! tensor(-0.0594, device='cuda:0')
we have a negative! tensor(-0.1314, device='cuda:0')
we have a negative! tensor(-0.2021, device='cuda:0')
we have a negative! tensor(-0.0170, device='cuda:0')
we have a negative! tensor(-0.1219, device='cuda:0')
we have a negative! tensor(-0.0997, device='cuda:0')
we have a negative! tensor(-0.0568, device='cuda:0')
we have a negative! tensor(-0.1436, device='cuda:0')
we have a negative! tensor(-0.1634, device='cuda:0')
we have a negative! tensor(-0.0279, device='cuda:0')
we have a negative! tensor(-0.1516, device='cuda:0')
we have a negative! tensor(-0.1622, device='cuda:0')
we have a negative! tensor(-0.1170, device='cuda:0')
we have a negative! tensor(-0.0290, device='cuda:0')
we have a negative! tensor(-0.1398, device='cuda:0')
we have a negative! tensor(-0.0535, device='cuda:0')
Epoch 00005: reducing learning rate of group 0 to 1.5900e-04.
32
32
32
we have a negative! tensor(-0.0286, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0302, device='cuda:0')
32
29
we have a negative! tensor(-0.0963, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0367, device='cuda:0')
we have a negative! tensor(-0.0388, device='cuda:0')
we have a negative! tensor(-0.0344, device='cuda:0')
we have a negative! tensor(-0.0014, device='cuda:0')
we have a negative! tensor(-0.0345, device='cuda:0')
we have a negative! tensor(-0.0335, device='cuda:0')
Epoch 00009: reducing learning rate of group 0 to 1.5900e-05.
we have a negative! tensor(-0.0377, device='cuda:0')
we have a negative! tensor(-0.0024, device='cuda:0')
we have a negative! tensor(-0.0374, device='cuda:0')
we have a negative! tensor(-0.0013, device='cuda:0')
32
32
32
we have a negative! tensor(-0.0418, device='cuda:0')
8
32
32
we have a negative! tensor(-0.0082, device='cuda:0')
32
we have a negative! tensor(-0.0420, device='cuda:0')
32
we have a negative! tensor(-0.0035, device='cuda:0')
29
we have a negative! tensor(-0.0062, device='cuda:0')
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0060, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0805, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0769, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0596, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0440, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0291, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0180, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0062, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0239, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0131, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0001, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0036, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0170, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0188, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0071, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0199, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0153, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0179, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0152, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0049, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0108, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
we have a negative! tensor(-0.0108, device='cuda:0')
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00007: reducing learning rate of group 0 to 1.4827e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.1226, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1750, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1163, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1037, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0877, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0547, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0901, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0953, device='cuda:0')
32
we have a negative! tensor(-0.1513, device='cuda:0')
32
we have a negative! tensor(-0.0024, device='cuda:0')
8
we have a negative! tensor(-0.0774, device='cuda:0')
32
we have a negative! tensor(-0.0780, device='cuda:0')
32
we have a negative! tensor(-0.0981, device='cuda:0')
32
32
we have a negative! tensor(-0.0098, device='cuda:0')
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00051: reducing learning rate of group 0 to 3.7684e-07.
32
32
32
8
32
32
32
32
29
Epoch 00056: reducing learning rate of group 0 to 3.7684e-08.
32
32
32
8
32
32
32
32
29
Epoch 00062: reducing learning rate of group 0 to 3.7684e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00045: reducing learning rate of group 0 to 1.3113e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
Epoch 00005: reducing learning rate of group 0 to 1.8435e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0556, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0294, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0129, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0187, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0528, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0395, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0583, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1951, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0215, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0564, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0605, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1921, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0074, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0807, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0404, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0241, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0108, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0594, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0021, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0927, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0952, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0389, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0254, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0726, device='cuda:0')
32
32
we have a negative! tensor(-0.1210, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0810, device='cuda:0')
32
29
we have a negative! tensor(-0.0730, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0697, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0537, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0648, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0683, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0048, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0019, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0399, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0354, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1121, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0055, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0660, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0796, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0376, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0400, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1139, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0442, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1235, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1954, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0168, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0019, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0138, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0606, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0242, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0382, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0307, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0942, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0397, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0191, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1100, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0215, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0687, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0846, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0055, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0459, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0005, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0772, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0930, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0624, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0391, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0207, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0080, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0192, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0247, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0926, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0702, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0735, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0009, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1226, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0063, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0894, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0682, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0096, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0733, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1228, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0447, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0226, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0393, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0934, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0359, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0771, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0546, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0256, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0566, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0666, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0401, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0336, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0311, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0256, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0178, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0935, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0832, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0175, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0705, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0334, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0540, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0442, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0174, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0110, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0439, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0034, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0565, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0640, device='cuda:0')
we have a negative! tensor(-0.0940, device='cuda:0')
we have a negative! tensor(-0.0736, device='cuda:0')
we have a negative! tensor(-0.0182, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0449, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0154, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0594, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0709, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0240, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0206, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1367, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0111, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0225, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0359, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0122, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1160, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0125, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0388, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1059, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0357, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1154, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0403, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0676, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0114, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0317, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0927, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1672, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0914, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0825, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0569, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0245, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0425, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0020, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0532, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0218, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0943, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0371, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0685, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0937, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0526, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0018, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0297, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0197, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0396, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0164, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0769, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0019, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0341, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0191, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0324, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0541, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0937, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1090, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0641, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1101, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1565, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0635, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0118, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0980, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0196, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0328, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0044, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0484, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0282, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0519, device='cuda:0')
we have a negative! tensor(-0.0706, device='cuda:0')
we have a negative! tensor(-0.0627, device='cuda:0')
we have a negative! tensor(-0.0706, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0339, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0899, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1398, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1509, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0252, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0038, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0019, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1098, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0134, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0475, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0526, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0161, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0425, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0130, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0283, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0224, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0818, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1448, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0763, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0907, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0907, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0283, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0185, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0514, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0993, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0765, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0015, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1030, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0630, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0617, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.2013, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0671, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0186, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0397, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0610, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0369, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0688, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0102, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0217, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0905, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0532, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0168, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0266, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0810, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1069, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0274, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0604, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0415, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0195, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0266, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0355, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0752, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0477, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0709, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0650, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0808, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0843, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0649, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0629, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0355, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0583, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0544, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0143, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0136, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0027, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-5.2402e-05, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0506, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0689, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0777, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0541, device='cuda:0')
we have a negative! tensor(-0.0706, device='cuda:0')
we have a negative! tensor(-0.0647, device='cuda:0')
Epoch 00004: reducing learning rate of group 0 to 3.5219e-07.
we have a negative! tensor(-0.2059, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0922, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0408, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1178, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0628, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0483, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0598, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0837, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0010, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0643, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0675, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0208, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0208, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0062, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0370, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1024, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0617, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0769, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0241, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0599, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1268, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1344, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0520, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0664, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1370, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0491, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1203, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0737, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0078, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0614, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0859, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0271, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1382, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0477, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0136, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0568, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0689, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0822, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0614, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0731, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0613, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0052, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0181, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0045, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0504, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0871, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0030, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1466, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0867, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0275, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0692, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0003, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0333, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0013, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0397, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0233, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0317, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0377, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0150, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0469, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0648, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0451, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0319, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1056, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0267, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0685, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0043, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0188, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0859, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0276, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0973, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0409, device='cuda:0')
we have a negative! tensor(-0.0616, device='cuda:0')
we have a negative! tensor(-0.0580, device='cuda:0')
we have a negative! tensor(-0.0423, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0301, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0589, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0326, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0253, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0233, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0468, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0230, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0353, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0352, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1430, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0288, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0070, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0372, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0141, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0381, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0730, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0640, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0730, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0163, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0458, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0071, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0725, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0373, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0293, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0283, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0041, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0502, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0322, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1064, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0048, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0460, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0907, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0640, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0483, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0308, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0134, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0883, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0255, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1064, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1310, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0249, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0695, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0431, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0144, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0170, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0410, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0028, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0063, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0215, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0318, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0209, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0092, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0692, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1557, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0469, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0105, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0189, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0324, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0155, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0171, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.1109, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0536, device='cuda:0', grad_fn=<SumBackward0>)
32
we have a negative! tensor(-0.0460, device='cuda:0')
32
32
we have a negative! tensor(-0.0645, device='cuda:0')
8
32
32
32
we have a negative! tensor(-0.0597, device='cuda:0')
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0928, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 3.1253e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 3.1253e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00039: reducing learning rate of group 0 to 3.1253e-06.
32
32
32
8
32
32
32
32
29
Epoch 00042: reducing learning rate of group 0 to 3.1253e-07.
Epoch 00045: reducing learning rate of group 0 to 3.1253e-08.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 8.3096e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00034: reducing learning rate of group 0 to 3.9208e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 1.9045e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.9045e-06.
Epoch 00030: reducing learning rate of group 0 to 1.9045e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0486, device='cuda:0', grad_fn=<SumBackward0>)
we have a negative! tensor(-0.0167, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00042: reducing learning rate of group 0 to 1.4433e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
we have a negative! tensor(-0.0122, device='cuda:0')
we have a negative! tensor(-0.0119, device='cuda:0')
we have a negative! tensor(-0.0102, device='cuda:0')
we have constant predictions!
we have a negative! tensor(-0.0103, device='cuda:0')
we have a negative! tensor(-0.0105, device='cuda:0')
we have a negative! tensor(-0.0142, device='cuda:0')
we have a negative! tensor(-0.0114, device='cuda:0')
we have a negative! tensor(-0.0112, device='cuda:0')
we have a negative! tensor(-0.0100, device='cuda:0')
we have a negative! tensor(-0.0206, device='cuda:0')
we have a negative! tensor(-0.0106, device='cuda:0')
we have a negative! tensor(-0.0235, device='cuda:0')
we have a negative! tensor(-0.0134, device='cuda:0')
we have a negative! tensor(-0.0183, device='cuda:0')
we have a negative! tensor(-0.0106, device='cuda:0')
we have a negative! tensor(-0.0174, device='cuda:0')
we have a negative! tensor(-0.0118, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 3.8771e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 4.8068e-05.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 4.8068e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 5.2557e-05.
Epoch 00020: reducing learning rate of group 0 to 5.2557e-06.
32
32
32
8
32
32
32
32
29
Epoch 00023: reducing learning rate of group 0 to 5.2557e-07.
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 5.2557e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 5.2612e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 5.2612e-06.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 5.2612e-07.
Epoch 00024: reducing learning rate of group 0 to 5.2612e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 4.7395e-05.
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 4.7395e-06.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 4.7395e-07.
Epoch 00024: reducing learning rate of group 0 to 4.7395e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 4.8280e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 4.8280e-06.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 4.8280e-07.
Epoch 00024: reducing learning rate of group 0 to 4.8280e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 4.5747e-05.
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 4.5747e-06.
Epoch 00020: reducing learning rate of group 0 to 4.5747e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 5.0283e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 5.0283e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 5.0121e-05.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 5.0121e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 4.8372e-05.
Epoch 00020: reducing learning rate of group 0 to 4.8372e-06.
32
32
32
8
32
32
32
32
29
Epoch 00023: reducing learning rate of group 0 to 4.8372e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 5.2945e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 5.2945e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 5.3680e-05.
32
32
32
8
32
32
32
32
29
Epoch 00024: reducing learning rate of group 0 to 5.3680e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 5.6503e-05.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 5.6503e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 5.4768e-05.
32
32
32
8
32
32
32
32
29
Epoch 00024: reducing learning rate of group 0 to 5.4768e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00010: reducing learning rate of group 0 to 7.0468e-05.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 7.0468e-06.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 7.0468e-07.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 7.0468e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 6.4089e-05.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 6.4089e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00030: reducing learning rate of group 0 to 3.9396e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 5.9053e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 5.9053e-06.
32
32
32
8
32
32
32
32
29
Epoch 00023: reducing learning rate of group 0 to 5.9053e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 6.5672e-05.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 6.5672e-06.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 6.5672e-07.
Epoch 00025: reducing learning rate of group 0 to 6.5672e-08.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 6.6249e-05.
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 6.6249e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 6.6249e-07.
Epoch 00024: reducing learning rate of group 0 to 6.6249e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
Epoch 00005: reducing learning rate of group 0 to 1.0307e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 9.9902e-05.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 9.9902e-06.
Epoch 00025: reducing learning rate of group 0 to 9.9902e-07.
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 9.9902e-08.
32
32
32
8
32
32
32
32
29
Epoch 00035: reducing learning rate of group 0 to 9.9902e-09.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.0289e-04.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 1.8757e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.8757e-05.
Epoch 00024: reducing learning rate of group 0 to 1.8757e-06.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.8757e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 2.0059e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00029: reducing learning rate of group 0 to 2.0059e-05.
32
32
32
8
32
32
32
32
29
Epoch 00033: reducing learning rate of group 0 to 2.0059e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.0852e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 1.0852e-05.
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 1.0852e-06.
Epoch 00035: reducing learning rate of group 0 to 1.0852e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
we have a negative! tensor(-0.1410, device='cuda:0')
32
we have a negative! tensor(-0.1418, device='cuda:0')
32
we have a negative! tensor(-0.1621, device='cuda:0')
8
we have a negative! tensor(-0.1308, device='cuda:0')
32
we have a negative! tensor(-0.1213, device='cuda:0')
32
we have a negative! tensor(-0.1482, device='cuda:0')
32
we have a negative! tensor(-0.1645, device='cuda:0')
32
we have a negative! tensor(-0.1388, device='cuda:0')
29
we have a negative! tensor(-0.1528, device='cuda:0')
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 9.4872e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 9.4872e-05.
Epoch 00025: reducing learning rate of group 0 to 9.4872e-06.
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 9.4872e-07.
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 9.4872e-08.
Epoch 00034: reducing learning rate of group 0 to 9.4872e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 2.1366e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00028: reducing learning rate of group 0 to 2.1366e-05.
32
32
32
8
32
32
32
32
29
Epoch 00031: reducing learning rate of group 0 to 2.1366e-06.
Epoch 00035: reducing learning rate of group 0 to 2.1366e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0331, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 1.0845e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 1.0845e-05.
32
32
32
8
32
32
32
32
29
Epoch 00023: reducing learning rate of group 0 to 1.0845e-06.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.0845e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 2.2766e-04.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 2.2766e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 9.9945e-05.
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 9.9945e-06.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 9.9945e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 1.9968e-04.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 1.9968e-05.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 1.9968e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.2557e-04.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 1.2557e-05.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.2557e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 1.3108e-04.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.3108e-05.
Epoch 00025: reducing learning rate of group 0 to 1.3108e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.2448e-04.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 1.2448e-05.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.2448e-06.
Epoch 00030: reducing learning rate of group 0 to 1.2448e-07.
32
32
32
8
32
32
32
32
29
Epoch 00033: reducing learning rate of group 0 to 1.2448e-08.
32
32
32
8
32
32
32
32
29
Epoch 00036: reducing learning rate of group 0 to 1.2448e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 1.0634e-04.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 1.0634e-05.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.0634e-06.
Epoch 00024: reducing learning rate of group 0 to 1.0634e-07.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.0634e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 9.8995e-05.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 9.8995e-06.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 9.8995e-07.
32
32
32
8
32
32
32
32
29
Epoch 00033: reducing learning rate of group 0 to 9.8995e-08.
32
32
32
8
32
32
32
32
29
Epoch 00036: reducing learning rate of group 0 to 9.8995e-09.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 1.0435e-04.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 1.0435e-05.
32
32
32
8
32
32
32
32
29
Epoch 00020: reducing learning rate of group 0 to 1.0435e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 2.2548e-04.
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 2.2548e-05.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 2.2548e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.9340e-04.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 1.9340e-05.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.9340e-06.
Epoch 00030: reducing learning rate of group 0 to 1.9340e-07.
32
32
32
8
32
32
32
32
29
Epoch 00035: reducing learning rate of group 0 to 1.9340e-08.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00012: reducing learning rate of group 0 to 1.9607e-04.
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 1.9607e-05.
32
32
32
8
32
32
32
32
29
Epoch 00025: reducing learning rate of group 0 to 1.9607e-06.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 1.3253e-04.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 1.3253e-05.
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 1.3253e-06.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 1.3253e-07.
Epoch 00025: reducing learning rate of group 0 to 1.3253e-08.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00008: reducing learning rate of group 0 to 9.4587e-05.
32
32
32
8
32
32
32
32
29
Epoch 00015: reducing learning rate of group 0 to 9.4587e-06.
32
32
32
8
32
32
32
32
29
Epoch 00019: reducing learning rate of group 0 to 9.4587e-07.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 9.4587e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00011: reducing learning rate of group 0 to 1.2171e-04.
32
32
32
8
32
32
32
32
29
Epoch 00016: reducing learning rate of group 0 to 1.2171e-05.
32
32
32
8
32
32
32
32
29
Epoch 00024: reducing learning rate of group 0 to 1.2171e-06.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.2171e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 7.8300e-05.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 7.8300e-06.
Epoch 00024: reducing learning rate of group 0 to 7.8300e-07.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 7.8300e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.0727e-04.
32
32
32
8
32
32
32
32
29
Epoch 00021: reducing learning rate of group 0 to 1.0727e-05.
Epoch 00024: reducing learning rate of group 0 to 1.0727e-06.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.0727e-07.
32
32
32
8
32
32
32
32
29
Epoch 00033: reducing learning rate of group 0 to 1.0727e-08.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00013: reducing learning rate of group 0 to 1.7875e-06.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 5.5872e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00035: reducing learning rate of group 0 to 5.5872e-07.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0948, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00009: reducing learning rate of group 0 to 7.2522e-05.
32
32
32
8
32
32
32
32
29
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00018: reducing learning rate of group 0 to 4.3255e-06.
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00026: reducing learning rate of group 0 to 4.3255e-07.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
we have a negative! tensor(-0.0711, device='cuda:0', grad_fn=<SumBackward0>)
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00006: reducing learning rate of group 0 to 8.5759e-05.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /glade/work/kdagon/conda-envs/s2sml-env/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
32
32
32
8
32
32
32
32
29
Epoch 00017: reducing learning rate of group 0 to 1.0748e-04.
32
32
32
8
32
32
32
32
29
Epoch 00022: reducing learning rate of group 0 to 1.0748e-05.
32
32
32
8
32
32
32
32
29
Epoch 00027: reducing learning rate of group 0 to 1.0748e-06.
32
32
32
8
32
32
32
32
29
Epoch 00032: reducing learning rate of group 0 to 1.0748e-07.
Epoch 00035: reducing learning rate of group 0 to 1.0748e-08.
