INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29293.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 14:56:19,706][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29293.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.3548983981573254e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 20
INFO:echo.src.base_objective:	trainer:weight_decay : 3.4613408493270094e-06
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 0
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 0 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 15:14:11,478][0m Trial 0 finished with values: [1.083511178019095, 4.211939991221113, 2.3411359797088305] and parameters: {'learning_rate': 1.3548983981573254e-05, 'norm': 'zscore', 'weight_decay': 3.4613408493270094e-06, 'train_batch_size': 20, 'training_loss': 'xsigmoid', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.5669352369174383e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 49
INFO:echo.src.base_objective:	trainer:weight_decay : 6.120061875024669e-09
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 1
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 1 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 15:37:51,775][0m Trial 1 finished with values: [1.0986838446794442, 1.8811997154711129, 1.4529551960167273] and parameters: {'learning_rate': 3.5669352369174383e-06, 'norm': 'minmax', 'weight_decay': 6.120061875024669e-09, 'train_batch_size': 49, 'training_loss': 'smooth', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 4.6344195535612443e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 4
INFO:echo.src.base_objective:	trainer:weight_decay : 1.0447417914055498e-07
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 2
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 2 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 15:52:08,955][0m Trial 2 finished with values: [1.0612703671027754, 1.3856854639236653, 1.1955605027943454] and parameters: {'learning_rate': 4.6344195535612443e-05, 'norm': 'minmax', 'weight_decay': 1.0447417914055498e-07, 'train_batch_size': 4, 'training_loss': 'xtanh', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004026600968340341
INFO:echo.src.base_objective:	trainer:train_batch_size : 36
INFO:echo.src.base_objective:	trainer:weight_decay : 1.688680100888438e-10
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 3
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 3 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 16:00:51,735][0m Trial 3 finished with values: [1.1948350099210727, 3.8002859171653958, 2.1802256663981634] and parameters: {'learning_rate': 0.004026600968340341, 'norm': 'zscore', 'weight_decay': 1.688680100888438e-10, 'train_batch_size': 36, 'training_loss': 'mse', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001547676565813708
INFO:echo.src.base_objective:	trainer:train_batch_size : 52
INFO:echo.src.base_objective:	trainer:weight_decay : 1.4854758080407468e-10
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 4
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 4 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 16:13:01,447][0m Trial 4 finished with values: [0.9570071098348536, 0.3439020664584843, 0.6406596770502122] and parameters: {'learning_rate': 0.001547676565813708, 'norm': 'minmax', 'weight_decay': 1.4854758080407468e-10, 'train_batch_size': 52, 'training_loss': 'xsigmoid', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0002807388496760832
INFO:echo.src.base_objective:	trainer:train_batch_size : 41
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00017240598667379932
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 5
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 5 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 16:27:41,324][0m Trial 5 finished with values: [0.9656692974660082, 0.4381996944033206, 0.7270406954212975] and parameters: {'learning_rate': 0.0002807388496760832, 'norm': 'minmax', 'weight_decay': 0.00017240598667379932, 'train_batch_size': 41, 'training_loss': 'smooth', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.4010690805632776e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 52
INFO:echo.src.base_objective:	trainer:weight_decay : 3.66615242098248e-10
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 6
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 6 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29293.gusched01.csv
[32m[I 2023-05-10 16:45:04,033][0m Trial 6 finished with values: [1.478399632524736, 16.427225072924248, 4.998763106286992] and parameters: {'learning_rate': 1.4010690805632776e-06, 'norm': 'minmax', 'weight_decay': 3.66615242098248e-10, 'train_batch_size': 52, 'training_loss': 'mse', 'model_name': 'fpn'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29294.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 16:46:03,037][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29294.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001258746498138382
INFO:echo.src.base_objective:	trainer:train_batch_size : 20
INFO:echo.src.base_objective:	trainer:weight_decay : 1.242582641464375e-12
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 7
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 7 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 16:55:41,067][0m Trial 7 finished with values: [1.0602752806182012, 1.3651128559248071, 1.168475963354797] and parameters: {'learning_rate': 0.001258746498138382, 'norm': 'minmax', 'weight_decay': 1.242582641464375e-12, 'train_batch_size': 20, 'training_loss': 'smooth', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00011975993884522177
INFO:echo.src.base_objective:	trainer:train_batch_size : 12
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0004903908171456615
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 8
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 8 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 17:00:07,704][0m Trial 8 finished with values: [1.131751189303451, 3.8038640679812192, 2.149307322592137] and parameters: {'learning_rate': 0.00011975993884522177, 'norm': 'zscore', 'weight_decay': 0.0004903908171456615, 'train_batch_size': 12, 'training_loss': 'xtanh', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0002554403241695504
INFO:echo.src.base_objective:	trainer:train_batch_size : 26
INFO:echo.src.base_objective:	trainer:weight_decay : 4.408748847385961e-10
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 9
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 9 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 17:10:00,155][0m Trial 9 finished with values: [1.0173762263889683, 0.974762679600298, 0.9416313350198077] and parameters: {'learning_rate': 0.0002554403241695504, 'norm': 'minmax', 'weight_decay': 4.408748847385961e-10, 'train_batch_size': 26, 'training_loss': 'mae', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00655709277514773
INFO:echo.src.base_objective:	trainer:train_batch_size : 47
INFO:echo.src.base_objective:	trainer:weight_decay : 5.68747731148446e-06
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 10
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 10 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 17:17:46,173][0m Trial 10 finished with values: [1.1546579330422124, 3.718474341092303, 2.1059878875155786] and parameters: {'learning_rate': 0.00655709277514773, 'norm': 'zscore', 'weight_decay': 5.68747731148446e-06, 'train_batch_size': 47, 'training_loss': 'huber', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 5.876499352538339e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 108
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00022842975844502254
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 11
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 11 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 17:47:58,884][0m Trial 11 finished with values: [1.115062384039545, 1.868601989723156, 1.514441017651845] and parameters: {'learning_rate': 5.876499352538339e-05, 'norm': 'negone', 'weight_decay': 0.00022842975844502254, 'train_batch_size': 108, 'training_loss': 'mse', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.9484567155587445e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 50
INFO:echo.src.base_objective:	trainer:weight_decay : 1.418165093097668e-05
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 12
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 12 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 17:50:55,849][0m Trial 12 finished with values: [12.115047625911009, 12089.610340382089, 162.55816974723555] and parameters: {'learning_rate': 3.9484567155587445e-05, 'norm': 'None', 'weight_decay': 1.418165093097668e-05, 'train_batch_size': 50, 'training_loss': 'smooth', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.951154740309098e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 67
INFO:echo.src.base_objective:	trainer:weight_decay : 1.9335257469934938e-08
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 13
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 13 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29294.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 18:20:12,967][0m Trial 13 finished with values: [1.1653507089250148, 8.602262860557335, 3.7891356180232667] and parameters: {'learning_rate': 2.951154740309098e-06, 'norm': 'negone', 'weight_decay': 1.9335257469934938e-08, 'train_batch_size': 67, 'training_loss': 'huber', 'model_name': 'deeplabv3+'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29295.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 18:21:12,272][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29295.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0008602458776901623
INFO:echo.src.base_objective:	trainer:train_batch_size : 65
INFO:echo.src.base_objective:	trainer:weight_decay : 4.1386239986853106e-07
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 14
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 14 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 18:34:23,828][0m Trial 14 finished with values: [0.9916059620507224, 0.8723889710149144, 0.8846414609736669] and parameters: {'learning_rate': 0.0008602458776901623, 'norm': 'negone', 'weight_decay': 4.1386239986853106e-07, 'train_batch_size': 65, 'training_loss': 'huber', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.108931132428922e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 68
INFO:echo.src.base_objective:	trainer:weight_decay : 2.47945056408929e-08
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 15
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 15 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 18:37:09,084][0m Trial 15 finished with values: [2.9256425798008103, 12131.921673050158, 162.84276821581213] and parameters: {'learning_rate': 2.108931132428922e-06, 'norm': 'None', 'weight_decay': 2.47945056408929e-08, 'train_batch_size': 68, 'training_loss': 'xtanh', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0008893855368110295
INFO:echo.src.base_objective:	trainer:train_batch_size : 75
INFO:echo.src.base_objective:	trainer:weight_decay : 1.4832865686309087e-09
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 16
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 16 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 18:49:30,168][0m Trial 16 finished with values: [0.9602456937599414, 0.37555441734269224, 0.6605959265894583] and parameters: {'learning_rate': 0.0008893855368110295, 'norm': 'minmax', 'weight_decay': 1.4832865686309087e-09, 'train_batch_size': 75, 'training_loss': 'mse', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.3653519472297794e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 70
INFO:echo.src.base_objective:	trainer:weight_decay : 8.081280317380018e-06
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 17
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 17 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 19:22:44,650][0m Trial 17 finished with values: [1.0797157126957706, 5.196142193398869, 2.6674931190249933] and parameters: {'learning_rate': 2.3653519472297794e-06, 'norm': 'zscore', 'weight_decay': 8.081280317380018e-06, 'train_batch_size': 70, 'training_loss': 'xsigmoid', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00037808941820237607
INFO:echo.src.base_objective:	trainer:train_batch_size : 48
INFO:echo.src.base_objective:	trainer:weight_decay : 6.157290656030438e-11
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 18
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 18 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 19:39:26,772][0m Trial 18 finished with values: [0.9907953848155664, 0.9738114919347339, 0.9646407489922999] and parameters: {'learning_rate': 0.00037808941820237607, 'norm': 'negone', 'weight_decay': 6.157290656030438e-11, 'train_batch_size': 48, 'training_loss': 'huber', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.506917968256088e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 39
INFO:echo.src.base_objective:	trainer:weight_decay : 4.412270593386939e-06
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 19
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 19 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 19:42:01,749][0m Trial 19 finished with values: [15.51499533270836, 12091.872406877543, 162.5734395722149] and parameters: {'learning_rate': 2.506917968256088e-06, 'norm': 'None', 'weight_decay': 4.412270593386939e-06, 'train_batch_size': 39, 'training_loss': 'xtanh', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004409058769438447
INFO:echo.src.base_objective:	trainer:train_batch_size : 108
INFO:echo.src.base_objective:	trainer:weight_decay : 2.95940885560841e-06
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 20
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 20 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29295.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 19:52:22,020][0m Trial 20 finished with values: [1.1401703786512243, 3.6934916744396142, 2.095031619953151] and parameters: {'learning_rate': 0.004409058769438447, 'norm': 'zscore', 'weight_decay': 2.95940885560841e-06, 'train_batch_size': 108, 'training_loss': 'xtanh', 'model_name': 'deeplabv3+'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29296.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 19:53:28,717][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29296.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.002303407577307165
INFO:echo.src.base_objective:	trainer:train_batch_size : 19
INFO:echo.src.base_objective:	trainer:weight_decay : 2.218964152196667e-08
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 21
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 21 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:03:01,073][0m Trial 21 finished with values: [1.1388554874953616, 3.667701841524662, 2.0843159233390645] and parameters: {'learning_rate': 0.002303407577307165, 'norm': 'zscore', 'weight_decay': 2.218964152196667e-08, 'train_batch_size': 19, 'training_loss': 'mae', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004668813412492273
INFO:echo.src.base_objective:	trainer:train_batch_size : 89
INFO:echo.src.base_objective:	trainer:weight_decay : 4.8373003391961337e-08
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 22
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 22 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:05:20,888][0m Trial 22 finished with values: [26.20750019741562, 12056.507611742445, 162.33530580550791] and parameters: {'learning_rate': 0.004668813412492273, 'norm': 'None', 'weight_decay': 4.8373003391961337e-08, 'train_batch_size': 89, 'training_loss': 'mae', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.243206692723839e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 91
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0004384422270597085
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 23
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 23 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:07:41,284][0m Trial 23 finished with values: [1.5687348452309964, 12079.09043114002, 162.48817328609832] and parameters: {'learning_rate': 3.243206692723839e-05, 'norm': 'None', 'weight_decay': 0.0004384422270597085, 'train_batch_size': 91, 'training_loss': 'huber', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0028365952354959907
INFO:echo.src.base_objective:	trainer:train_batch_size : 55
INFO:echo.src.base_objective:	trainer:weight_decay : 3.870820376340573e-06
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 24
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 24 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:18:27,919][0m Trial 24 finished with values: [0.9927522128695282, 0.9063513049742883, 0.9214278353803503] and parameters: {'learning_rate': 0.0028365952354959907, 'norm': 'negone', 'weight_decay': 3.870820376340573e-06, 'train_batch_size': 55, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00019534907387375866
INFO:echo.src.base_objective:	trainer:train_batch_size : 104
INFO:echo.src.base_objective:	trainer:weight_decay : 7.943170672947882e-05
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 25
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 25 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:37:54,354][0m Trial 25 finished with values: [0.9613712960476408, 0.3872332027621462, 0.6779033044011005] and parameters: {'learning_rate': 0.00019534907387375866, 'norm': 'minmax', 'weight_decay': 7.943170672947882e-05, 'train_batch_size': 104, 'training_loss': 'smooth', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0027569193269758557
INFO:echo.src.base_objective:	trainer:train_batch_size : 74
INFO:echo.src.base_objective:	trainer:weight_decay : 7.271017544806836e-09
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 26
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 26 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:44:28,759][0m Trial 26 finished with values: [1.0763274439328396, 1.5603077065465099, 1.2681775512153997] and parameters: {'learning_rate': 0.0027569193269758557, 'norm': 'minmax', 'weight_decay': 7.271017544806836e-09, 'train_batch_size': 74, 'training_loss': 'logcosh', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.6120174161463345e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 48
INFO:echo.src.base_objective:	trainer:weight_decay : 8.761710225656118e-08
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 27
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 27 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 20:58:29,158][0m Trial 27 finished with values: [1.0250473399889317, 1.0960719402930061, 1.0547501875453893] and parameters: {'learning_rate': 2.6120174161463345e-05, 'norm': 'minmax', 'weight_decay': 8.761710225656118e-08, 'train_batch_size': 48, 'training_loss': 'xsigmoid', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.2598608965307476e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 98
INFO:echo.src.base_objective:	trainer:weight_decay : 5.7463562467015685e-09
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 28
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 28 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:13:51,507][0m Trial 28 finished with values: [1.0434219198587977, 4.513229156603377, 2.450455903476583] and parameters: {'learning_rate': 3.2598608965307476e-05, 'norm': 'zscore', 'weight_decay': 5.7463562467015685e-09, 'train_batch_size': 98, 'training_loss': 'smooth', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.006902008135543711
INFO:echo.src.base_objective:	trainer:train_batch_size : 70
INFO:echo.src.base_objective:	trainer:weight_decay : 1.3430497319346132e-05
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 29
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 29 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29296.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:22:01,576][0m Trial 29 finished with values: [1.1985431276346166, 3.810236425633841, 2.183038534662334] and parameters: {'learning_rate': 0.006902008135543711, 'norm': 'zscore', 'weight_decay': 1.3430497319346132e-05, 'train_batch_size': 70, 'training_loss': 'smooth', 'model_name': 'pspnet'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29297.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 21:22:31,935][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29297.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.3350598805998322e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 102
INFO:echo.src.base_objective:	trainer:weight_decay : 3.5689189882705246e-05
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 30
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 30 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:25:04,994][0m Trial 30 finished with values: [9.668377981368685, 12099.916176664628, 162.62759342721415] and parameters: {'learning_rate': 1.3350598805998322e-06, 'norm': 'None', 'weight_decay': 3.5689189882705246e-05, 'train_batch_size': 102, 'training_loss': 'xtanh', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.003429011616458314
INFO:echo.src.base_objective:	trainer:train_batch_size : 81
INFO:echo.src.base_objective:	trainer:weight_decay : 2.423478407526899e-07
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 31
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 31 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:39:26,829][0m Trial 31 finished with values: [0.9597936037993839, 0.3742766438060768, 0.6638993356342773] and parameters: {'learning_rate': 0.003429011616458314, 'norm': 'minmax', 'weight_decay': 2.423478407526899e-07, 'train_batch_size': 81, 'training_loss': 'huber', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001200900352834607
INFO:echo.src.base_objective:	trainer:train_batch_size : 66
INFO:echo.src.base_objective:	trainer:weight_decay : 2.1681180923603377e-09
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 32
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 32 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:52:55,122][0m Trial 32 finished with values: [1.063874441481388, 1.3950535714939885, 1.1891412981464924] and parameters: {'learning_rate': 0.001200900352834607, 'norm': 'minmax', 'weight_decay': 2.1681180923603377e-09, 'train_batch_size': 66, 'training_loss': 'logcosh', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00024940856210925797
INFO:echo.src.base_objective:	trainer:train_batch_size : 92
INFO:echo.src.base_objective:	trainer:weight_decay : 4.358413390331373e-05
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 33
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 33 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 21:58:48,715][0m Trial 33 finished with values: [1.0631863795583842, 3.9438254407837654, 2.2270286828849626] and parameters: {'learning_rate': 0.00024940856210925797, 'norm': 'zscore', 'weight_decay': 4.358413390331373e-05, 'train_batch_size': 92, 'training_loss': 'huber', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 6.945872191253874e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 15
INFO:echo.src.base_objective:	trainer:weight_decay : 1.2133550032632996e-05
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 34
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 34 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 22:09:21,543][0m Trial 34 finished with values: [1.15913191293403, 3.6987314659850767, 2.0955733799130583] and parameters: {'learning_rate': 6.945872191253874e-05, 'norm': 'zscore', 'weight_decay': 1.2133550032632996e-05, 'train_batch_size': 15, 'training_loss': 'logcosh', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 6.158606568456797e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 71
INFO:echo.src.base_objective:	trainer:weight_decay : 1.4441551544094618e-11
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 35
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 35 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 22:31:21,183][0m Trial 35 finished with values: [1.0799132246027359, 4.829458101712185, 2.7487424712280437] and parameters: {'learning_rate': 6.158606568456797e-06, 'norm': 'negone', 'weight_decay': 1.4441551544094618e-11, 'train_batch_size': 71, 'training_loss': 'xtanh', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.005242076961473581
INFO:echo.src.base_objective:	trainer:train_batch_size : 15
INFO:echo.src.base_objective:	trainer:weight_decay : 1.2240232255734478e-10
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 36
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 36 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 22:34:25,642][0m Trial 36 finished with values: [19.429500324321914, 12056.524078893177, 162.33541862603917] and parameters: {'learning_rate': 0.005242076961473581, 'norm': 'None', 'weight_decay': 1.2240232255734478e-10, 'train_batch_size': 15, 'training_loss': 'xsigmoid', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.0512151950645914e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 49
INFO:echo.src.base_objective:	trainer:weight_decay : 2.526939604259813e-10
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 37
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 37 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 22:46:25,679][0m Trial 37 finished with values: [1.1121720940232809, 5.4061445219957225, 2.90211251283661] and parameters: {'learning_rate': 1.0512151950645914e-05, 'norm': 'negone', 'weight_decay': 2.526939604259813e-10, 'train_batch_size': 49, 'training_loss': 'xsigmoid', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 7.287067182953151e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 100
INFO:echo.src.base_objective:	trainer:weight_decay : 1.3346395095121e-08
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 38
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 38 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29297.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 22:58:41,939][0m Trial 38 finished with values: [1.0956184093352206, 1.8592967907772981, 1.4323860724709319] and parameters: {'learning_rate': 7.287067182953151e-05, 'norm': 'negone', 'weight_decay': 1.3346395095121e-08, 'train_batch_size': 100, 'training_loss': 'logcosh', 'model_name': 'deeplabv3'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29298.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-10 22:59:05,123][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29298.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0072490196277495
INFO:echo.src.base_objective:	trainer:train_batch_size : 124
INFO:echo.src.base_objective:	trainer:weight_decay : 1.0353330777974389e-08
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 39
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 39 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:08:26,831][0m Trial 39 finished with values: [1.1040006720910274, 3.5915107776943542, 2.0439192407464555] and parameters: {'learning_rate': 0.0072490196277495, 'norm': 'zscore', 'weight_decay': 1.0353330777974389e-08, 'train_batch_size': 124, 'training_loss': 'huber', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 9.715863722653073e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 37
INFO:echo.src.base_objective:	trainer:weight_decay : 1.7150262270018178e-06
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 40
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 40 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:11:19,941][0m Trial 40 finished with values: [1.1821352349644012, 4.135949483473327, 2.2941864509289926] and parameters: {'learning_rate': 9.715863722653073e-05, 'norm': 'zscore', 'weight_decay': 1.7150262270018178e-06, 'train_batch_size': 37, 'training_loss': 'mse', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.560555723321865e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 35
INFO:echo.src.base_objective:	trainer:weight_decay : 3.1213742246874556e-10
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 41
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 41 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:39:07,347][0m Trial 41 finished with values: [1.1750445181283957, 2.278344107452871, 1.7023107303849059] and parameters: {'learning_rate': 2.560555723321865e-06, 'norm': 'negone', 'weight_decay': 3.1213742246874556e-10, 'train_batch_size': 35, 'training_loss': 'xsigmoid', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0014553995022737968
INFO:echo.src.base_objective:	trainer:train_batch_size : 26
INFO:echo.src.base_objective:	trainer:weight_decay : 4.544515838616384e-05
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 42
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 42 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:42:29,785][0m Trial 42 finished with values: [8.00923257390426, 12063.968386614099, 162.38600995580168] and parameters: {'learning_rate': 0.0014553995022737968, 'norm': 'None', 'weight_decay': 4.544515838616384e-05, 'train_batch_size': 26, 'training_loss': 'huber', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 4.756235974445481e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 97
INFO:echo.src.base_objective:	trainer:weight_decay : 4.31011899628292e-10
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 43
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 43 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:45:00,268][0m Trial 43 finished with values: [3.063593433406798, 12104.942124406823, 162.66178238743365] and parameters: {'learning_rate': 4.756235974445481e-06, 'norm': 'None', 'weight_decay': 4.31011899628292e-10, 'train_batch_size': 97, 'training_loss': 'mse', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0015260563568063028
INFO:echo.src.base_objective:	trainer:train_batch_size : 100
INFO:echo.src.base_objective:	trainer:weight_decay : 1.3616285900262955e-08
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 44
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 44 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-10 23:49:02,526][0m Trial 44 finished with values: [1.0920944097722924, 3.6995077811561776, 2.111026512378038] and parameters: {'learning_rate': 0.0015260563568063028, 'norm': 'zscore', 'weight_decay': 1.3616285900262955e-08, 'train_batch_size': 100, 'training_loss': 'mae', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00043486736435603934
INFO:echo.src.base_objective:	trainer:train_batch_size : 32
INFO:echo.src.base_objective:	trainer:weight_decay : 2.416197256975403e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 45
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 45 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:01:40,548][0m Trial 45 finished with values: [0.957387102078354, 0.3446952176097325, 0.6363686131392381] and parameters: {'learning_rate': 0.00043486736435603934, 'norm': 'minmax', 'weight_decay': 2.416197256975403e-11, 'train_batch_size': 32, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0017235933650785339
INFO:echo.src.base_objective:	trainer:train_batch_size : 101
INFO:echo.src.base_objective:	trainer:weight_decay : 9.213343344190401e-11
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 46
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 46 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:19:56,928][0m Trial 46 finished with values: [1.040936357506005, 1.2634817554391995, 1.0916361607049014] and parameters: {'learning_rate': 0.0017235933650785339, 'norm': 'negone', 'weight_decay': 9.213343344190401e-11, 'train_batch_size': 101, 'training_loss': 'mae', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.7446477800418518e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 73
INFO:echo.src.base_objective:	trainer:weight_decay : 1.451122759800014e-09
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 47
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 47 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29298.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:32:25,397][0m Trial 47 finished with values: [1.179026534859718, 4.161479313179862, 2.286701685900739] and parameters: {'learning_rate': 2.7446477800418518e-05, 'norm': 'zscore', 'weight_decay': 1.451122759800014e-09, 'train_batch_size': 73, 'training_loss': 'huber', 'model_name': 'deeplabv3'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29299.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 00:32:48,274][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29299.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00026950999511929277
INFO:echo.src.base_objective:	trainer:train_batch_size : 66
INFO:echo.src.base_objective:	trainer:weight_decay : 6.040018439812538e-09
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 48
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 48 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:40:57,142][0m Trial 48 finished with values: [1.0853920769972059, 1.6204964944583073, 1.2970570458888928] and parameters: {'learning_rate': 0.00026950999511929277, 'norm': 'negone', 'weight_decay': 6.040018439812538e-09, 'train_batch_size': 66, 'training_loss': 'mae', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0028952674594194643
INFO:echo.src.base_objective:	trainer:train_batch_size : 128
INFO:echo.src.base_objective:	trainer:weight_decay : 4.620624798136605e-11
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 49
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 49 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:47:44,640][0m Trial 49 finished with values: [1.1033863689291674, 3.6030756666672503, 2.0492147094875124] and parameters: {'learning_rate': 0.0028952674594194643, 'norm': 'zscore', 'weight_decay': 4.620624798136605e-11, 'train_batch_size': 128, 'training_loss': 'xtanh', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 7.257098472707323e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 121
INFO:echo.src.base_objective:	trainer:weight_decay : 2.1059078664356417e-08
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 50
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 50 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 00:53:07,775][0m Trial 50 finished with values: [1.1864437391214149, 4.725716598757882, 2.5087276450271085] and parameters: {'learning_rate': 7.257098472707323e-05, 'norm': 'zscore', 'weight_decay': 2.1059078664356417e-08, 'train_batch_size': 121, 'training_loss': 'xsigmoid', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 9.889190670322e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 118
INFO:echo.src.base_objective:	trainer:weight_decay : 5.563319961596876e-08
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 51
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 51 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 01:11:27,942][0m Trial 51 finished with values: [0.998524838696792, 1.549943433468789, 1.3671500084551569] and parameters: {'learning_rate': 9.889190670322e-05, 'norm': 'negone', 'weight_decay': 5.563319961596876e-08, 'train_batch_size': 118, 'training_loss': 'xsigmoid', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.007455690702098068
INFO:echo.src.base_objective:	trainer:train_batch_size : 26
INFO:echo.src.base_objective:	trainer:weight_decay : 5.07155115456202e-12
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 52
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 52 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 01:21:29,192][0m Trial 52 finished with values: [1.01463580290188, 0.9476014809661479, 0.9212238288246776] and parameters: {'learning_rate': 0.007455690702098068, 'norm': 'minmax', 'weight_decay': 5.07155115456202e-12, 'train_batch_size': 26, 'training_loss': 'huber', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0001890055198273664
INFO:echo.src.base_objective:	trainer:train_batch_size : 101
INFO:echo.src.base_objective:	trainer:weight_decay : 5.834621475620575e-06
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 53
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 53 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 01:34:47,311][0m Trial 53 finished with values: [1.015907002944075, 0.964318991753005, 0.9383776043690129] and parameters: {'learning_rate': 0.0001890055198273664, 'norm': 'minmax', 'weight_decay': 5.834621475620575e-06, 'train_batch_size': 101, 'training_loss': 'xsigmoid', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.6039757860759994e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 125
INFO:echo.src.base_objective:	trainer:weight_decay : 1.0074397369802193e-09
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 54
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 54 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29299.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:09:00,990][0m Trial 54 finished with values: [1.107820580566006, 5.0187712576552865, 2.6275076774258976] and parameters: {'learning_rate': 3.6039757860759994e-06, 'norm': 'zscore', 'weight_decay': 1.0074397369802193e-09, 'train_batch_size': 125, 'training_loss': 'logcosh', 'model_name': 'manet'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29300.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 02:10:05,553][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29300.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.1883997969026672e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 55
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0001031486182584722
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 55
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 55 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:13:05,742][0m Trial 55 finished with values: [8.121399511168045, 12101.465822217835, 162.63786009555776] and parameters: {'learning_rate': 2.1883997969026672e-05, 'norm': 'None', 'weight_decay': 0.0001031486182584722, 'train_batch_size': 55, 'training_loss': 'mse', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00028230705715962
INFO:echo.src.base_objective:	trainer:train_batch_size : 24
INFO:echo.src.base_objective:	trainer:weight_decay : 2.986112205500461e-07
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 56
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 56 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:22:41,547][0m Trial 56 finished with values: [1.0817644416562386, 1.6031011509625503, 1.2700036594148512] and parameters: {'learning_rate': 0.00028230705715962, 'norm': 'negone', 'weight_decay': 2.986112205500461e-07, 'train_batch_size': 24, 'training_loss': 'smooth', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.196358909902674e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 42
INFO:echo.src.base_objective:	trainer:weight_decay : 4.3571121360021945e-10
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 57
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 57 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:37:57,253][0m Trial 57 finished with values: [1.030510891935001, 1.2289270249148612, 1.1517781855623668] and parameters: {'learning_rate': 2.196358909902674e-05, 'norm': 'minmax', 'weight_decay': 4.3571121360021945e-10, 'train_batch_size': 42, 'training_loss': 'smooth', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.007048579992028126
INFO:echo.src.base_objective:	trainer:train_batch_size : 6
INFO:echo.src.base_objective:	trainer:weight_decay : 4.0946315456983936e-08
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 58
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 58 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:51:04,983][0m Trial 58 finished with values: [1.0768776304003835, 1.6066917708852178, 1.2637269115315968] and parameters: {'learning_rate': 0.007048579992028126, 'norm': 'negone', 'weight_decay': 4.0946315456983936e-08, 'train_batch_size': 6, 'training_loss': 'mae', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00030771930257469276
INFO:echo.src.base_objective:	trainer:train_batch_size : 45
INFO:echo.src.base_objective:	trainer:weight_decay : 1.00438766639592e-08
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 59
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 59 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:53:33,028][0m Trial 59 finished with values: [9.03882885982357, 12056.697417321948, 162.33658588461248] and parameters: {'learning_rate': 0.00030771930257469276, 'norm': 'None', 'weight_decay': 1.00438766639592e-08, 'train_batch_size': 45, 'training_loss': 'xtanh', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004959492953216965
INFO:echo.src.base_objective:	trainer:train_batch_size : 62
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00021879272338152107
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 60
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 60 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 02:57:40,679][0m Trial 60 finished with values: [2.486072760469984, 12056.508767331969, 162.33531448401033] and parameters: {'learning_rate': 0.004959492953216965, 'norm': 'None', 'weight_decay': 0.00021879272338152107, 'train_batch_size': 62, 'training_loss': 'xtanh', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.0408588226170338e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 108
INFO:echo.src.base_objective:	trainer:weight_decay : 1.011708817690221e-09
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 61
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 61 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 03:31:50,896][0m Trial 61 finished with values: [1.0442012287706763, 4.592138331110943, 2.47503965967543] and parameters: {'learning_rate': 1.0408588226170338e-05, 'norm': 'zscore', 'weight_decay': 1.011708817690221e-09, 'train_batch_size': 108, 'training_loss': 'xsigmoid', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.2820408239553284e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 102
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0006839597384025426
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 62
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 62 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29300.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 03:44:49,976][0m Trial 62 finished with values: [1.0925063650875468, 2.333544586726199, 1.757947628114529] and parameters: {'learning_rate': 1.2820408239553284e-05, 'norm': 'minmax', 'weight_decay': 0.0006839597384025426, 'train_batch_size': 102, 'training_loss': 'xtanh', 'model_name': 'deeplabv3+'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29301.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 03:45:48,486][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29301.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0008052474331700542
INFO:echo.src.base_objective:	trainer:train_batch_size : 127
INFO:echo.src.base_objective:	trainer:weight_decay : 6.806193434353103e-09
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 63
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 63 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 03:50:10,686][0m Trial 63 finished with values: [36217.91492135772, 12100.211140890919, 162.62757173095815] and parameters: {'learning_rate': 0.0008052474331700542, 'norm': 'None', 'weight_decay': 6.806193434353103e-09, 'train_batch_size': 127, 'training_loss': 'huber', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.423438134327314e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 46
INFO:echo.src.base_objective:	trainer:weight_decay : 7.578711901169819e-09
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 64
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 64 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 03:52:39,290][0m Trial 64 finished with values: [6.755134882008502, 12133.838796072358, 162.85550825734077] and parameters: {'learning_rate': 1.423438134327314e-06, 'norm': 'None', 'weight_decay': 7.578711901169819e-09, 'train_batch_size': 46, 'training_loss': 'smooth', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 2.5381430615836986e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 78
INFO:echo.src.base_objective:	trainer:weight_decay : 7.473596556792399e-11
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 65
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 65 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 04:26:22,294][0m Trial 65 finished with values: [1.2257703048214537, 3.91123834000882, 2.2006562464551505] and parameters: {'learning_rate': 2.5381430615836986e-06, 'norm': 'zscore', 'weight_decay': 7.473596556792399e-11, 'train_batch_size': 78, 'training_loss': 'xtanh', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0032241365564022522
INFO:echo.src.base_objective:	trainer:train_batch_size : 66
INFO:echo.src.base_objective:	trainer:weight_decay : 3.2650410508867e-11
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 66
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 66 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 04:30:19,437][0m Trial 66 finished with values: [127.91340588588837, 12056.537079275335, 162.3355054110632] and parameters: {'learning_rate': 0.0032241365564022522, 'norm': 'None', 'weight_decay': 3.2650410508867e-11, 'train_batch_size': 66, 'training_loss': 'xsigmoid', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.808535096663436e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 75
INFO:echo.src.base_objective:	trainer:weight_decay : 7.940965071491093e-12
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 67
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 67 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 04:37:53,848][0m Trial 67 finished with values: [12.663014732855684, 24.600871403753462, 5.525497205110187] and parameters: {'learning_rate': 3.808535096663436e-06, 'norm': 'minmax', 'weight_decay': 7.940965071491093e-12, 'train_batch_size': 75, 'training_loss': 'mse', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004508363943049777
INFO:echo.src.base_objective:	trainer:train_batch_size : 62
INFO:echo.src.base_objective:	trainer:weight_decay : 4.0161504968463736e-07
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 68
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 68 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 04:57:29,484][0m Trial 68 finished with values: [0.9598975411793804, 0.37476556817569184, 0.6604199577027416] and parameters: {'learning_rate': 0.004508363943049777, 'norm': 'minmax', 'weight_decay': 4.0161504968463736e-07, 'train_batch_size': 62, 'training_loss': 'mse', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 9.612327184800803e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 29
INFO:echo.src.base_objective:	trainer:weight_decay : 3.735083479733766e-10
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 69
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 69 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 04:59:59,982][0m Trial 69 finished with values: [3.636560598982861, 12065.635324504106, 162.39730936593133] and parameters: {'learning_rate': 9.612327184800803e-06, 'norm': 'None', 'weight_decay': 3.735083479733766e-10, 'train_batch_size': 29, 'training_loss': 'logcosh', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.2311762612224088e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 99
INFO:echo.src.base_objective:	trainer:weight_decay : 5.233445223836726e-12
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 70
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 70 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29301.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 05:28:44,964][0m Trial 70 finished with values: [1.3964520099391493, 3.9182448948535398, 2.236579914933047] and parameters: {'learning_rate': 1.2311762612224088e-05, 'norm': 'minmax', 'weight_decay': 5.233445223836726e-12, 'train_batch_size': 99, 'training_loss': 'logcosh', 'model_name': 'manet'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29302.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 05:29:10,762][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29302.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.1292614347148496e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 21
INFO:echo.src.base_objective:	trainer:weight_decay : 1.6168982555379746e-06
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 71
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 71 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 05:35:10,233][0m Trial 71 finished with values: [1.0438399630819108, 4.395071828465246, 2.4070528669198366] and parameters: {'learning_rate': 3.1292614347148496e-05, 'norm': 'zscore', 'weight_decay': 1.6168982555379746e-06, 'train_batch_size': 21, 'training_loss': 'mse', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 4.8239065605886275e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 74
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0007853091153196584
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 72
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 72 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:11:06,816][0m Trial 72 finished with values: [1.0809631725061333, 6.264962620529071, 3.2419612418999644] and parameters: {'learning_rate': 4.8239065605886275e-06, 'norm': 'negone', 'weight_decay': 0.0007853091153196584, 'train_batch_size': 74, 'training_loss': 'mae', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00017778964355196058
INFO:echo.src.base_objective:	trainer:train_batch_size : 126
INFO:echo.src.base_objective:	trainer:weight_decay : 3.0409159527147e-09
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 73
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 73 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:16:12,381][0m Trial 73 finished with values: [1.164304197030964, 4.609601440127016, 2.4710455779891785] and parameters: {'learning_rate': 0.00017778964355196058, 'norm': 'zscore', 'weight_decay': 3.0409159527147e-09, 'train_batch_size': 126, 'training_loss': 'huber', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0003279398944665208
INFO:echo.src.base_objective:	trainer:train_batch_size : 61
INFO:echo.src.base_objective:	trainer:weight_decay : 3.0890784593504974e-09
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 74
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 74 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:24:20,404][0m Trial 74 finished with values: [1.0836390861996608, 1.6005705175011948, 1.2820609761530704] and parameters: {'learning_rate': 0.0003279398944665208, 'norm': 'negone', 'weight_decay': 3.0890784593504974e-09, 'train_batch_size': 61, 'training_loss': 'huber', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.004152059092265649
INFO:echo.src.base_objective:	trainer:train_batch_size : 113
INFO:echo.src.base_objective:	trainer:weight_decay : 1.2660158119643377e-08
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 75
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 75 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:36:36,737][0m Trial 75 finished with values: [1.1037427044773174, 3.588163026473811, 2.0388950434304096] and parameters: {'learning_rate': 0.004152059092265649, 'norm': 'zscore', 'weight_decay': 1.2660158119643377e-08, 'train_batch_size': 113, 'training_loss': 'xtanh', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00014220681054283568
INFO:echo.src.base_objective:	trainer:train_batch_size : 33
INFO:echo.src.base_objective:	trainer:weight_decay : 1.8111673670835495e-11
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 76
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 76 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:44:43,637][0m Trial 76 finished with values: [1.16432175235691, 3.910844424832384, 2.19997228009784] and parameters: {'learning_rate': 0.00014220681054283568, 'norm': 'zscore', 'weight_decay': 1.8111673670835495e-11, 'train_batch_size': 33, 'training_loss': 'smooth', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.2493049468216726e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 31
INFO:echo.src.base_objective:	trainer:weight_decay : 1.4247715464603723e-09
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 77
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 77 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29302.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:55:52,787][0m Trial 77 finished with values: [1.0864858754193372, 4.679731308590762, 2.700621483514501] and parameters: {'learning_rate': 1.2493049468216726e-05, 'norm': 'negone', 'weight_decay': 1.4247715464603723e-09, 'train_batch_size': 31, 'training_loss': 'mse', 'model_name': 'deeplabv3+'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29303.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 06:56:18,292][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29303.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.005063107619297649
INFO:echo.src.base_objective:	trainer:train_batch_size : 84
INFO:echo.src.base_objective:	trainer:weight_decay : 3.943862478784006e-10
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 78
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 78 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 06:59:56,741][0m Trial 78 finished with values: [32.50837859742976, 12056.570013576802, 162.3357223736233] and parameters: {'learning_rate': 0.005063107619297649, 'norm': 'None', 'weight_decay': 3.943862478784006e-10, 'train_batch_size': 84, 'training_loss': 'mae', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0003266921352040603
INFO:echo.src.base_objective:	trainer:train_batch_size : 93
INFO:echo.src.base_objective:	trainer:weight_decay : 1.9800097972386807e-06
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 79
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 79 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 07:02:18,666][0m Trial 79 finished with values: [3.416676744753702, 12057.274345392372, 162.34050422844774] and parameters: {'learning_rate': 0.0003266921352040603, 'norm': 'None', 'weight_decay': 1.9800097972386807e-06, 'train_batch_size': 93, 'training_loss': 'huber', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.007480966246918205
INFO:echo.src.base_objective:	trainer:train_batch_size : 49
INFO:echo.src.base_objective:	trainer:weight_decay : 5.172674160325877e-06
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 80
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 80 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 07:23:46,710][0m Trial 80 finished with values: [0.9618690303631297, 0.3985078613253062, 0.6830091695880637] and parameters: {'learning_rate': 0.007480966246918205, 'norm': 'minmax', 'weight_decay': 5.172674160325877e-06, 'train_batch_size': 49, 'training_loss': 'huber', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 9.828151627432369e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 83
INFO:echo.src.base_objective:	trainer:weight_decay : 2.732128729400272e-09
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 81
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 81 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 07:57:01,341][0m Trial 81 finished with values: [1.0428655317292164, 4.50829106282033, 2.4470361276107533] and parameters: {'learning_rate': 9.828151627432369e-06, 'norm': 'zscore', 'weight_decay': 2.732128729400272e-09, 'train_batch_size': 83, 'training_loss': 'mse', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001516989299684817
INFO:echo.src.base_objective:	trainer:train_batch_size : 99
INFO:echo.src.base_objective:	trainer:weight_decay : 9.064274968687644e-05
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 82
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 82 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 08:00:12,660][0m Trial 82 finished with values: [10.543798673087215, 84.2483725130408, 13.046016045350006] and parameters: {'learning_rate': 0.001516989299684817, 'norm': 'minmax', 'weight_decay': 9.064274968687644e-05, 'train_batch_size': 99, 'training_loss': 'huber', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 7.891025767227172e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 37
INFO:echo.src.base_objective:	trainer:weight_decay : 5.336046030288526e-06
INFO:echo.src.base_objective:	trainer:training_loss : mse
INFO:echo.src.base_objective:Beginning trial 83
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 83 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 08:03:33,216][0m Trial 83 finished with values: [1.1821589763998757, 3.929216465529627, 2.2150776975101047] and parameters: {'learning_rate': 7.891025767227172e-05, 'norm': 'zscore', 'weight_decay': 5.336046030288526e-06, 'train_batch_size': 37, 'training_loss': 'mse', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0002597260194933242
INFO:echo.src.base_objective:	trainer:train_batch_size : 90
INFO:echo.src.base_objective:	trainer:weight_decay : 2.8968496567313772e-05
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 84
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 84 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 08:11:06,378][0m Trial 84 finished with values: [1.064438514355781, 3.905288061748051, 2.201860946580695] and parameters: {'learning_rate': 0.0002597260194933242, 'norm': 'zscore', 'weight_decay': 2.8968496567313772e-05, 'train_batch_size': 90, 'training_loss': 'smooth', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 6.046143842792285e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 110
INFO:echo.src.base_objective:	trainer:weight_decay : 1.2446154003273245e-08
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 85
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 85 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29303.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 08:45:31,585][0m Trial 85 finished with values: [1.0554896119894555, 4.877259461587045, 2.5701261937781092] and parameters: {'learning_rate': 6.046143842792285e-06, 'norm': 'zscore', 'weight_decay': 1.2446154003273245e-08, 'train_batch_size': 110, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29304.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 08:46:36,253][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29304.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 7.293883255701389e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 9
INFO:echo.src.base_objective:	trainer:weight_decay : 3.9863254111285986e-12
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 86
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 86 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 08:52:30,407][0m Trial 86 finished with values: [1.039486784950891, 1.5363719434103658, 1.2772897028893286] and parameters: {'learning_rate': 7.293883255701389e-05, 'norm': 'negone', 'weight_decay': 3.9863254111285986e-12, 'train_batch_size': 9, 'training_loss': 'logcosh', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 4.560638978759699e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 76
INFO:echo.src.base_objective:	trainer:weight_decay : 3.436289606289613e-05
INFO:echo.src.base_objective:	trainer:training_loss : mae
INFO:echo.src.base_objective:Beginning trial 87
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 87 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 09:18:00,524][0m Trial 87 finished with values: [1.1663251185511145, 4.794776790316289, 2.5303052150239855] and parameters: {'learning_rate': 4.560638978759699e-06, 'norm': 'zscore', 'weight_decay': 3.436289606289613e-05, 'train_batch_size': 76, 'training_loss': 'mae', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0015900333284344548
INFO:echo.src.base_objective:	trainer:train_batch_size : 40
INFO:echo.src.base_objective:	trainer:weight_decay : 3.3465294689368225e-06
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 88
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 88 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 09:22:36,068][0m Trial 88 finished with values: [41.278596846718834, 12058.032989915622, 162.34557681310272] and parameters: {'learning_rate': 0.0015900333284344548, 'norm': 'None', 'weight_decay': 3.3465294689368225e-06, 'train_batch_size': 40, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00014827007638569404
INFO:echo.src.base_objective:	trainer:train_batch_size : 19
INFO:echo.src.base_objective:	trainer:weight_decay : 7.260787765373819e-09
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 89
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 89 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 09:26:23,985][0m Trial 89 finished with values: [15.071987933012506, 12065.513120911824, 162.39601626907316] and parameters: {'learning_rate': 0.00014827007638569404, 'norm': 'None', 'weight_decay': 7.260787765373819e-09, 'train_batch_size': 19, 'training_loss': 'xtanh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.7683681148160743e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 29
INFO:echo.src.base_objective:	trainer:weight_decay : 2.5754128362219433e-09
INFO:echo.src.base_objective:	trainer:training_loss : smooth
INFO:echo.src.base_objective:Beginning trial 90
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 90 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 09:58:50,280][0m Trial 90 finished with values: [1.098901517145578, 1.7152711864899224, 1.3582913148889428] and parameters: {'learning_rate': 3.7683681148160743e-06, 'norm': 'negone', 'weight_decay': 2.5754128362219433e-09, 'train_batch_size': 29, 'training_loss': 'smooth', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.3112678511467874e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 27
INFO:echo.src.base_objective:	trainer:weight_decay : 7.93892501078798e-09
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 91
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 91 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29304.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 10:21:12,906][0m Trial 91 finished with values: [0.9662844037620776, 0.4473834693174413, 0.7487878245016139] and parameters: {'learning_rate': 1.3112678511467874e-05, 'norm': 'minmax', 'weight_decay': 7.93892501078798e-09, 'train_batch_size': 27, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29305.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 10:22:09,434][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29305.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.8434662032708008e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 92
INFO:echo.src.base_objective:	trainer:weight_decay : 1.2296631251932242e-07
INFO:echo.src.base_objective:	trainer:training_loss : xtanh
INFO:echo.src.base_objective:Beginning trial 92
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 92 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 10:26:06,150][0m Trial 92 finished with values: [2.4059399005427875, 27.9761234119555, 6.930457598046473] and parameters: {'learning_rate': 1.8434662032708008e-06, 'norm': 'negone', 'weight_decay': 1.2296631251932242e-07, 'train_batch_size': 92, 'training_loss': 'xtanh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : None
INFO:echo.src.base_objective:	model:name : pspnet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.5218923506442593e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 6
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00039926934486922096
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 93
INFO:root:Loading model pspnet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 93 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 10:28:42,856][0m Trial 93 finished with values: [21.673036089654822, 12065.742794329944, 162.3974916144818] and parameters: {'learning_rate': 3.5218923506442593e-06, 'norm': 'None', 'weight_decay': 0.00039926934486922096, 'train_batch_size': 6, 'training_loss': 'xsigmoid', 'model_name': 'pspnet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0031253150244401765
INFO:echo.src.base_objective:	trainer:train_batch_size : 114
INFO:echo.src.base_objective:	trainer:weight_decay : 1.1981139745365596e-10
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 94
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 94 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 10:49:46,880][0m Trial 94 finished with values: [1.070913669545951, 1.45247120783001, 1.2222953123890836] and parameters: {'learning_rate': 0.0031253150244401765, 'norm': 'minmax', 'weight_decay': 1.1981139745365596e-10, 'train_batch_size': 114, 'training_loss': 'huber', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0008309573354251212
INFO:echo.src.base_objective:	trainer:train_batch_size : 106
INFO:echo.src.base_objective:	trainer:weight_decay : 1.3453287745905944e-07
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 95
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 95 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 10:54:53,797][0m Trial 95 finished with values: [1.0786845588220548, 3.7403192646520074, 2.1210721109740027] and parameters: {'learning_rate': 0.0008309573354251212, 'norm': 'zscore', 'weight_decay': 1.3453287745905944e-07, 'train_batch_size': 106, 'training_loss': 'huber', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : zscore
INFO:echo.src.base_objective:	model:name : manet
INFO:echo.src.base_objective:	optimizer:learning_rate : 3.920820387290148e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 12
INFO:echo.src.base_objective:	trainer:weight_decay : 1.0099803364918285e-11
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 96
INFO:root:Loading model manet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 96 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 11:12:36,821][0m Trial 96 finished with values: [1.06644919905303, 4.10384342941689, 2.2975030530617477] and parameters: {'learning_rate': 3.920820387290148e-06, 'norm': 'zscore', 'weight_decay': 1.0099803364918285e-11, 'train_batch_size': 12, 'training_loss': 'huber', 'model_name': 'manet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : fpn
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0001904524195090763
INFO:echo.src.base_objective:	trainer:train_batch_size : 102
INFO:echo.src.base_objective:	trainer:weight_decay : 1.9705492780477393e-07
INFO:echo.src.base_objective:	trainer:training_loss : huber
INFO:echo.src.base_objective:Beginning trial 97
INFO:root:Loading model fpn with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 97 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 11:26:22,341][0m Trial 97 finished with values: [1.0330190279438731, 2.135183840629913, 1.6185306973004565] and parameters: {'learning_rate': 0.0001904524195090763, 'norm': 'minmax', 'weight_decay': 1.9705492780477393e-07, 'train_batch_size': 102, 'training_loss': 'huber', 'model_name': 'fpn'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.443262446132864e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 50
INFO:echo.src.base_objective:	trainer:weight_decay : 2.6798261635092496e-06
INFO:echo.src.base_objective:	trainer:training_loss : xsigmoid
INFO:echo.src.base_objective:Beginning trial 98
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 98 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29305.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 11:48:57,913][0m Trial 98 finished with values: [1.0581501464130147, 2.7739093933061096, 1.9567348824866284] and parameters: {'learning_rate': 1.443262446132864e-05, 'norm': 'negone', 'weight_decay': 2.6798261635092496e-06, 'train_batch_size': 50, 'training_loss': 'xsigmoid', 'model_name': 'deeplabv3+'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29306.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 11:50:00,790][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29306.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : negone
INFO:echo.src.base_objective:	model:name : deeplabv3+
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.003877142404604691
INFO:echo.src.base_objective:	trainer:train_batch_size : 117
INFO:echo.src.base_objective:	trainer:weight_decay : 2.2718076157350836e-07
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 99
INFO:root:Loading model deeplabv3+ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 99 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 12:04:08,893][0m Trial 99 finished with values: [1.0404345061182558, 1.2714339698122537, 1.0995020122849755] and parameters: {'learning_rate': 0.003877142404604691, 'norm': 'negone', 'weight_decay': 2.2718076157350836e-07, 'train_batch_size': 117, 'training_loss': 'logcosh', 'model_name': 'deeplabv3+'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00048068489537828426
INFO:echo.src.base_objective:	trainer:train_batch_size : 41
INFO:echo.src.base_objective:	trainer:weight_decay : 4.802596202763959e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 100
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 100 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 12:14:49,246][0m Trial 100 finished with values: [0.9577603980744976, 0.3547400736204951, 0.65522185856596] and parameters: {'learning_rate': 0.00048068489537828426, 'norm': 'minmax', 'weight_decay': 4.802596202763959e-11, 'train_batch_size': 41, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005255729344740429
INFO:echo.src.base_objective:	trainer:train_batch_size : 43
INFO:echo.src.base_objective:	trainer:weight_decay : 2.9598315432876316e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 101
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 101 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 12:27:17,786][0m Trial 101 finished with values: [0.9571673843365893, 0.3392425824071751, 0.6357225520521441] and parameters: {'learning_rate': 0.0005255729344740429, 'norm': 'minmax', 'weight_decay': 2.9598315432876316e-11, 'train_batch_size': 43, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005261176328814102
INFO:echo.src.base_objective:	trainer:train_batch_size : 44
INFO:echo.src.base_objective:	trainer:weight_decay : 3.8227658332100756e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 102
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 102 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 12:39:00,136][0m Trial 102 finished with values: [0.9573143167485197, 0.3409533825898599, 0.6375017342069512] and parameters: {'learning_rate': 0.0005261176328814102, 'norm': 'minmax', 'weight_decay': 3.8227658332100756e-11, 'train_batch_size': 44, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00047394641243643385
INFO:echo.src.base_objective:	trainer:train_batch_size : 44
INFO:echo.src.base_objective:	trainer:weight_decay : 2.7740578990108866e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 103
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 103 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 12:50:43,204][0m Trial 103 finished with values: [0.9578639249498845, 0.34761069970433367, 0.6412049598061716] and parameters: {'learning_rate': 0.00047394641243643385, 'norm': 'minmax', 'weight_decay': 2.7740578990108866e-11, 'train_batch_size': 44, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0004828020210797112
INFO:echo.src.base_objective:	trainer:train_batch_size : 43
INFO:echo.src.base_objective:	trainer:weight_decay : 3.997693652757779e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 104
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 104 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:02:30,573][0m Trial 104 finished with values: [0.9580598506265613, 0.34918269948823794, 0.6444614428063462] and parameters: {'learning_rate': 0.0004828020210797112, 'norm': 'minmax', 'weight_decay': 3.997693652757779e-11, 'train_batch_size': 43, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0004574670457733144
INFO:echo.src.base_objective:	trainer:train_batch_size : 43
INFO:echo.src.base_objective:	trainer:weight_decay : 2.8309463706789842e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 105
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 105 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:11:49,893][0m Trial 105 finished with values: [0.9582975958682012, 0.35271760064428986, 0.6461364440002912] and parameters: {'learning_rate': 0.0004574670457733144, 'norm': 'minmax', 'weight_decay': 2.8309463706789842e-11, 'train_batch_size': 43, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005028347921566055
INFO:echo.src.base_objective:	trainer:train_batch_size : 43
INFO:echo.src.base_objective:	trainer:weight_decay : 2.6095887762866386e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 106
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 106 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29306.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:22:54,082][0m Trial 106 finished with values: [0.9578491907436397, 0.35011535984806935, 0.6442425251710668] and parameters: {'learning_rate': 0.0005028347921566055, 'norm': 'minmax', 'weight_decay': 2.6095887762866386e-11, 'train_batch_size': 43, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29307.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 13:24:08,826][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29307.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005012112448330442
INFO:echo.src.base_objective:	trainer:train_batch_size : 55
INFO:echo.src.base_objective:	trainer:weight_decay : 4.0817348662476314e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 107
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 107 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:35:56,632][0m Trial 107 finished with values: [0.957223288234943, 0.34712525271350286, 0.6417891686462158] and parameters: {'learning_rate': 0.0005012112448330442, 'norm': 'minmax', 'weight_decay': 4.0817348662476314e-11, 'train_batch_size': 55, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.00048371597430271523
INFO:echo.src.base_objective:	trainer:train_batch_size : 44
INFO:echo.src.base_objective:	trainer:weight_decay : 2.4459247992038762e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 108
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 108 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:46:43,033][0m Trial 108 finished with values: [0.9578611015938194, 0.3474784680775856, 0.6440686129849855] and parameters: {'learning_rate': 0.00048371597430271523, 'norm': 'minmax', 'weight_decay': 2.4459247992038762e-11, 'train_batch_size': 44, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005294480607932845
INFO:echo.src.base_objective:	trainer:train_batch_size : 54
INFO:echo.src.base_objective:	trainer:weight_decay : 4.1800813998166126e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 109
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 109 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 13:55:56,486][0m Trial 109 finished with values: [0.9581758612159696, 0.34882954728542476, 0.6412925813023591] and parameters: {'learning_rate': 0.0005294480607932845, 'norm': 'minmax', 'weight_decay': 4.1800813998166126e-11, 'train_batch_size': 54, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005368007769889669
INFO:echo.src.base_objective:	trainer:train_batch_size : 44
INFO:echo.src.base_objective:	trainer:weight_decay : 5.153022870767592e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 110
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 110 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 14:08:08,160][0m Trial 110 finished with values: [0.9571626562265144, 0.34072478441058596, 0.6379957809206113] and parameters: {'learning_rate': 0.0005368007769889669, 'norm': 'minmax', 'weight_decay': 5.153022870767592e-11, 'train_batch_size': 44, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005650323374495693
INFO:echo.src.base_objective:	trainer:train_batch_size : 54
INFO:echo.src.base_objective:	trainer:weight_decay : 1.9424138884105735e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 111
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 111 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 14:19:12,796][0m Trial 111 finished with values: [0.9567633729479434, 0.3402024582562608, 0.6371989304067854] and parameters: {'learning_rate': 0.0005650323374495693, 'norm': 'minmax', 'weight_decay': 1.9424138884105735e-11, 'train_batch_size': 54, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005476792814002746
INFO:echo.src.base_objective:	trainer:train_batch_size : 56
INFO:echo.src.base_objective:	trainer:weight_decay : 4.9320270837502616e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 112
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 112 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 14:31:09,656][0m Trial 112 finished with values: [0.9585445302188801, 0.3537422659200892, 0.6438146255793128] and parameters: {'learning_rate': 0.0005476792814002746, 'norm': 'minmax', 'weight_decay': 4.9320270837502616e-11, 'train_batch_size': 56, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0007046776075453445
INFO:echo.src.base_objective:	trainer:train_batch_size : 53
INFO:echo.src.base_objective:	trainer:weight_decay : 2.162480460568408e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 113
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 113 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 14:41:15,499][0m Trial 113 finished with values: [0.957995803044168, 0.34947458525959413, 0.6465458635319242] and parameters: {'learning_rate': 0.0007046776075453445, 'norm': 'minmax', 'weight_decay': 2.162480460568408e-11, 'train_batch_size': 53, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0006408926284840119
INFO:echo.src.base_objective:	trainer:train_batch_size : 59
INFO:echo.src.base_objective:	trainer:weight_decay : 6.195436171760605e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 114
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 114 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29307.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 14:51:33,465][0m Trial 114 finished with values: [0.957830942719353, 0.3499646149514262, 0.6454387385553305] and parameters: {'learning_rate': 0.0006408926284840119, 'norm': 'minmax', 'weight_decay': 6.195436171760605e-11, 'train_batch_size': 59, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29308.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 14:52:37,486][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29308.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0003939630491543955
INFO:echo.src.base_objective:	trainer:train_batch_size : 45
INFO:echo.src.base_objective:	trainer:weight_decay : 1.810413310330112e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 115
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 115 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 15:07:32,799][0m Trial 115 finished with values: [0.960561874897988, 0.3789769861808616, 0.6707260392183171] and parameters: {'learning_rate': 0.0003939630491543955, 'norm': 'minmax', 'weight_decay': 1.810413310330112e-11, 'train_batch_size': 45, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0005905276084987053
INFO:echo.src.base_objective:	trainer:train_batch_size : 34
INFO:echo.src.base_objective:	trainer:weight_decay : 3.406088709391692e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 116
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 116 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 15:18:53,859][0m Trial 116 finished with values: [0.9571201200199266, 0.34002330482416093, 0.6360811438570451] and parameters: {'learning_rate': 0.0005905276084987053, 'norm': 'minmax', 'weight_decay': 3.406088709391692e-11, 'train_batch_size': 34, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.000656717832317009
INFO:echo.src.base_objective:	trainer:train_batch_size : 32
INFO:echo.src.base_objective:	trainer:weight_decay : 3.243046197083327e-11
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 117
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 117 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 15:31:23,936][0m Trial 117 finished with values: [0.9571258754746196, 0.34114056452111063, 0.6377959180118069] and parameters: {'learning_rate': 0.000656717832317009, 'norm': 'minmax', 'weight_decay': 3.243046197083327e-11, 'train_batch_size': 32, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0006624863426782652
INFO:echo.src.base_objective:	trainer:train_batch_size : 33
INFO:echo.src.base_objective:	trainer:weight_decay : 2.1976936023496766e-12
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 118
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 118 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 15:42:52,413][0m Trial 118 finished with values: [0.9575957951153304, 0.34529797613186153, 0.6417789758798316] and parameters: {'learning_rate': 0.0006624863426782652, 'norm': 'minmax', 'weight_decay': 2.1976936023496766e-12, 'train_batch_size': 33, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.0307437674003906e-06
INFO:echo.src.base_objective:	trainer:train_batch_size : 57
INFO:echo.src.base_objective:	trainer:weight_decay : 1.0222996218951566e-06
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 119
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 119 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 15:46:12,149][0m Trial 119 finished with values: [2.3174589567509467, 54.963039611112976, 9.830205147117157] and parameters: {'learning_rate': 1.0307437674003906e-06, 'norm': 'minmax', 'weight_decay': 1.0222996218951566e-06, 'train_batch_size': 57, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0009990226164039709
INFO:echo.src.base_objective:	trainer:train_batch_size : 34
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0009837749814867978
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 120
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 120 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 16:03:12,334][0m Trial 120 finished with values: [0.9565289691255009, 0.33267511570758596, 0.6270693319530856] and parameters: {'learning_rate': 0.0009990226164039709, 'norm': 'minmax', 'weight_decay': 0.0009837749814867978, 'train_batch_size': 34, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001028854094138859
INFO:echo.src.base_objective:	trainer:train_batch_size : 33
INFO:echo.src.base_objective:	trainer:weight_decay : 8.761770896809859e-07
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 121
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 121 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 16:13:53,511][0m Trial 121 finished with values: [0.9600864550453906, 0.37722832432604503, 0.6655529380679348] and parameters: {'learning_rate': 0.001028854094138859, 'norm': 'minmax', 'weight_decay': 8.761770896809859e-07, 'train_batch_size': 33, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0018757393636350131
INFO:echo.src.base_objective:	trainer:train_batch_size : 33
INFO:echo.src.base_objective:	trainer:weight_decay : 0.000948996219535422
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 122
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 122 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29308.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 16:26:25,129][0m Trial 122 finished with values: [0.9571038524253683, 0.34447436370389645, 0.6366668196085717] and parameters: {'learning_rate': 0.0018757393636350131, 'norm': 'minmax', 'weight_decay': 0.000948996219535422, 'train_batch_size': 33, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29309.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 16:27:29,418][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29309.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0020058812352878514
INFO:echo.src.base_objective:	trainer:train_batch_size : 34
INFO:echo.src.base_objective:	trainer:weight_decay : 0.000984604867847954
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 123
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 123 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 16:43:52,120][0m Trial 123 finished with values: [0.9569921818022025, 0.34419493122951844, 0.6340675280754003] and parameters: {'learning_rate': 0.0020058812352878514, 'norm': 'minmax', 'weight_decay': 0.000984604867847954, 'train_batch_size': 34, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0010851773092239011
INFO:echo.src.base_objective:	trainer:train_batch_size : 33
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0009490189524101072
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 124
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 124 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 17:00:56,223][0m Trial 124 finished with values: [0.9566290178283335, 0.33353286680173916, 0.6273622151972453] and parameters: {'learning_rate': 0.0010851773092239011, 'norm': 'minmax', 'weight_decay': 0.0009490189524101072, 'train_batch_size': 33, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.009487219164811603
INFO:echo.src.base_objective:	trainer:train_batch_size : 34
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0009275992961296069
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 125
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 125 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 17:16:57,655][0m Trial 125 finished with values: [0.9610318596105049, 0.3878571448722881, 0.6706075672125987] and parameters: {'learning_rate': 0.009487219164811603, 'norm': 'minmax', 'weight_decay': 0.0009275992961296069, 'train_batch_size': 34, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.002136550703729929
INFO:echo.src.base_objective:	trainer:train_batch_size : 31
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0009368642907714234
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 126
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 126 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 17:34:22,659][0m Trial 126 finished with values: [0.9567495968414717, 0.33964475126411314, 0.6289661392368787] and parameters: {'learning_rate': 0.002136550703729929, 'norm': 'minmax', 'weight_decay': 0.0009368642907714234, 'train_batch_size': 31, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0010844941556412751
INFO:echo.src.base_objective:	trainer:train_batch_size : 30
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0008938485918497455
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 127
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 127 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 17:47:53,171][0m Trial 127 finished with values: [0.9600500253661208, 0.3777524997019841, 0.6672234931590356] and parameters: {'learning_rate': 0.0010844941556412751, 'norm': 'minmax', 'weight_decay': 0.0008938485918497455, 'train_batch_size': 30, 'training_loss': 'logcosh', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.002276613620420808
INFO:echo.src.base_objective:	trainer:train_batch_size : 39
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0003180866160183589
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 128
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 128 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29309.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 18:00:23,219][0m Trial 128 finished with values: [0.9587372724536621, 0.3635470248915616, 0.6534179052667355] and parameters: {'learning_rate': 0.002276613620420808, 'norm': 'minmax', 'weight_decay': 0.0003180866160183589, 'train_batch_size': 39, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29310.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 18:01:28,284][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29310.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0009994500335915612
INFO:echo.src.base_objective:	trainer:train_batch_size : 24
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005842692068326532
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 129
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 129 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 18:14:31,313][0m Trial 129 finished with values: [0.9568216360340441, 0.34118701612590024, 0.6325574712478544] and parameters: {'learning_rate': 0.0009994500335915612, 'norm': 'minmax', 'weight_decay': 0.0005842692068326532, 'train_batch_size': 24, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0019967687136332405
INFO:echo.src.base_objective:	trainer:train_batch_size : 38
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005934013912762972
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 130
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 130 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 18:27:09,270][0m Trial 130 finished with values: [0.9579608114393476, 0.35635625471244475, 0.6507715667065294] and parameters: {'learning_rate': 0.0019967687136332405, 'norm': 'minmax', 'weight_decay': 0.0005934013912762972, 'train_batch_size': 38, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0012556526788267174
INFO:echo.src.base_objective:	trainer:train_batch_size : 36
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005175317540521543
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 131
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 131 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 18:40:35,083][0m Trial 131 finished with values: [0.9568185253600908, 0.335474710908413, 0.6245356582438626] and parameters: {'learning_rate': 0.0012556526788267174, 'norm': 'minmax', 'weight_decay': 0.0005175317540521543, 'train_batch_size': 36, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0013107744879953826
INFO:echo.src.base_objective:	trainer:train_batch_size : 36
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0002985500196063587
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 132
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 132 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 18:53:08,314][0m Trial 132 finished with values: [0.9570373489682377, 0.34408864484871493, 0.6372169265373452] and parameters: {'learning_rate': 0.0013107744879953826, 'norm': 'minmax', 'weight_decay': 0.0002985500196063587, 'train_batch_size': 36, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0012448313586854787
INFO:echo.src.base_objective:	trainer:train_batch_size : 36
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00032703752201938233
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 133
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 133 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 19:10:19,525][0m Trial 133 finished with values: [0.9568197725618413, 0.33681736510468707, 0.6271995543734635] and parameters: {'learning_rate': 0.0012448313586854787, 'norm': 'minmax', 'weight_decay': 0.00032703752201938233, 'train_batch_size': 36, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.001063374137242226
INFO:echo.src.base_objective:	trainer:train_batch_size : 23
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005890682498500773
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 134
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 134 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 19:23:07,892][0m Trial 134 finished with values: [0.9570244604049062, 0.3437457423163649, 0.6366665473981935] and parameters: {'learning_rate': 0.001063374137242226, 'norm': 'minmax', 'weight_decay': 0.0005890682498500773, 'train_batch_size': 23, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.000989948857353205
INFO:echo.src.base_objective:	trainer:train_batch_size : 24
INFO:echo.src.base_objective:	trainer:weight_decay : 0.000583390467666541
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 135
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 135 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29310.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 19:40:27,565][0m Trial 135 finished with values: [0.9568053052214314, 0.33617992402765995, 0.6279851232793923] and parameters: {'learning_rate': 0.000989948857353205, 'norm': 'minmax', 'weight_decay': 0.000583390467666541, 'train_batch_size': 24, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29311.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 19:40:54,646][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29311.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0010435001757850423
INFO:echo.src.base_objective:	trainer:train_batch_size : 29
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0001696975231429007
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 136
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 136 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 19:51:21,378][0m Trial 136 finished with values: [0.9574209793077013, 0.3442976314537957, 0.6394035773827413] and parameters: {'learning_rate': 0.0010435001757850423, 'norm': 'minmax', 'weight_decay': 0.0001696975231429007, 'train_batch_size': 29, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.002254838616721136
INFO:echo.src.base_objective:	trainer:train_batch_size : 36
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00038150254145597075
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 137
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 137 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 20:03:46,533][0m Trial 137 finished with values: [0.9573182238130677, 0.34773860127515865, 0.639860195169397] and parameters: {'learning_rate': 0.002254838616721136, 'norm': 'minmax', 'weight_decay': 0.00038150254145597075, 'train_batch_size': 36, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0019340145401974644
INFO:echo.src.base_objective:	trainer:train_batch_size : 39
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0006137433130792426
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 138
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 138 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 20:20:39,113][0m Trial 138 finished with values: [0.9571452125474551, 0.34088956865386477, 0.6310741515285686] and parameters: {'learning_rate': 0.0019340145401974644, 'norm': 'minmax', 'weight_decay': 0.0006137433130792426, 'train_batch_size': 39, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0019606619382437547
INFO:echo.src.base_objective:	trainer:train_batch_size : 38
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005607767798894827
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 139
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 139 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 20:33:11,865][0m Trial 139 finished with values: [0.9577682930299947, 0.35317254775985013, 0.6479027415305295] and parameters: {'learning_rate': 0.0019606619382437547, 'norm': 'minmax', 'weight_decay': 0.0005607767798894827, 'train_batch_size': 38, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0013253323499503216
INFO:echo.src.base_objective:	trainer:train_batch_size : 29
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0002915569169651037
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 140
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 140 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 20:45:48,048][0m Trial 140 finished with values: [0.9573700909133677, 0.3454926216197966, 0.6390579004480068] and parameters: {'learning_rate': 0.0013253323499503216, 'norm': 'minmax', 'weight_decay': 0.0002915569169651037, 'train_batch_size': 29, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0009458715450642753
INFO:echo.src.base_objective:	trainer:train_batch_size : 35
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0009839149043112223
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 141
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 141 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 20:56:34,669][0m Trial 141 finished with values: [0.957530487028661, 0.3517313619830887, 0.6473359087862947] and parameters: {'learning_rate': 0.0009458715450642753, 'norm': 'minmax', 'weight_decay': 0.0009839149043112223, 'train_batch_size': 35, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0012170641713974176
INFO:echo.src.base_objective:	trainer:train_batch_size : 24
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00014508263030182906
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 142
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 142 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29311.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 21:09:12,038][0m Trial 142 finished with values: [0.9570085189947349, 0.3448728972788764, 0.6372500303438958] and parameters: {'learning_rate': 0.0012170641713974176, 'norm': 'minmax', 'weight_decay': 0.00014508263030182906, 'train_batch_size': 24, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
INFO:root:Saving trial details to /glade/work/kdagon/s2sml/results_week3_SH_510/
INFO:root:Running on PBS/SLURM batch id: 29312.gusched01
INFO:root:Importing custom objective from /glade/work/kdagon/s2sml/applications/train.py
INFO:echo.src.reporting:Using device 0
INFO:root:Direction of optimization: ['minimize', 'minimize', 'minimize']
INFO:root:Using metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
[32m[I 2023-05-11 21:09:35,028][0m Using an existing study with name 'vanilla' instead of creating a new one.[0m
INFO:root:Loaded study vanilla located at sqlite:////glade/work/kdagon/s2sml/results_week3_SH_510/s2s.db
INFO:echo.src.base_objective:Worker 29312.gusched01 is summoned.
INFO:echo.src.base_objective:	initializing an objective to be optimized with metric ['valid_custom', 'valid_custom_second', 'valid_custom_third']
INFO:echo.src.base_objective:	using device(s) cuda:0
INFO:echo.src.base_objective:	saving study/trial results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:root:Running optimization for 1000 trials
INFO:root:Running trials for a maximum PBS wall-time 2:00:00
WARNING:root:Attempting to run trials and stop before hitting the wall-time
WARNING:root:Some trials may not complete if the wall-time is reached. Optuna will start over.
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0007830040537547258
INFO:echo.src.base_objective:	trainer:train_batch_size : 41
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00041775646515502943
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 143
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 143 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 21:22:11,977][0m Trial 143 finished with values: [0.9569470482530434, 0.3395270362024817, 0.6354976609113429] and parameters: {'learning_rate': 0.0007830040537547258, 'norm': 'minmax', 'weight_decay': 0.00041775646515502943, 'train_batch_size': 41, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0010726531674515136
INFO:echo.src.base_objective:	trainer:train_batch_size : 24
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0005689157970995411
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 144
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 144 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 21:38:29,360][0m Trial 144 finished with values: [0.9565769963438612, 0.33177635891366153, 0.6229792349152274] and parameters: {'learning_rate': 0.0010726531674515136, 'norm': 'minmax', 'weight_decay': 0.0005689157970995411, 'train_batch_size': 24, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 1.787519835459144e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 14
INFO:echo.src.base_objective:	trainer:weight_decay : 3.103041550976799e-08
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 145
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 145 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 21:45:46,492][0m Trial 145 finished with values: [1.185257380557157, 2.62881010357985, 1.8041512566607234] and parameters: {'learning_rate': 1.787519835459144e-05, 'norm': 'minmax', 'weight_decay': 3.103041550976799e-08, 'train_batch_size': 14, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : linknet
INFO:echo.src.base_objective:	optimizer:learning_rate : 5.5871983375504115e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 16
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00012872002645525896
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 146
INFO:root:Loading model linknet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 146 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 22:03:26,128][0m Trial 146 finished with values: [0.9749773881471544, 0.5408263779090624, 0.8117412532680747] and parameters: {'learning_rate': 5.5871983375504115e-05, 'norm': 'minmax', 'weight_decay': 0.00012872002645525896, 'train_batch_size': 16, 'training_loss': 'logcosh', 'model_name': 'linknet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0007252204333117963
INFO:echo.src.base_objective:	trainer:train_batch_size : 11
INFO:echo.src.base_objective:	trainer:weight_decay : 1.1047959970484158e-12
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 147
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 147 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 22:08:55,309][0m Trial 147 finished with values: [0.9647653345803944, 0.44499379777386844, 0.7371637457031214] and parameters: {'learning_rate': 0.0007252204333117963, 'norm': 'minmax', 'weight_decay': 1.1047959970484158e-12, 'train_batch_size': 11, 'training_loss': 'logcosh', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : deeplabv3
INFO:echo.src.base_objective:	optimizer:learning_rate : 4.325506782049963e-05
INFO:echo.src.base_objective:	trainer:train_batch_size : 7
INFO:echo.src.base_objective:	trainer:weight_decay : 0.00023340188229107722
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 148
INFO:root:Loading model deeplabv3 with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 148 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 22:23:30,167][0m Trial 148 finished with values: [1.0627180372122407, 1.4080805131580856, 1.207747421918192] and parameters: {'learning_rate': 4.325506782049963e-05, 'norm': 'minmax', 'weight_decay': 0.00023340188229107722, 'train_batch_size': 7, 'training_loss': 'logcosh', 'model_name': 'deeplabv3'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0008575881475295273
INFO:echo.src.base_objective:	trainer:train_batch_size : 17
INFO:echo.src.base_objective:	trainer:weight_decay : 0.0003942414957412481
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 149
INFO:root:Loading model unet with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 149 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 22:27:24,164][0m Trial 149 finished with values: [0.9667991941804872, 0.4530689801208045, 0.7387008118493057] and parameters: {'learning_rate': 0.0008575881475295273, 'norm': 'minmax', 'weight_decay': 0.0003942414957412481, 'train_batch_size': 17, 'training_loss': 'logcosh', 'model_name': 'unet'}. [0m
INFO:echo.src.base_objective:Attempting to automatically update the model configuration using optuna's suggested parameters
INFO:echo.src.base_objective:	data:norm : minmax
INFO:echo.src.base_objective:	model:name : unet++
INFO:echo.src.base_objective:	optimizer:learning_rate : 0.0010748279727402954
INFO:echo.src.base_objective:	trainer:train_batch_size : 22
INFO:echo.src.base_objective:	trainer:weight_decay : 0.000572774199384401
INFO:echo.src.base_objective:	trainer:training_loss : logcosh
INFO:echo.src.base_objective:Beginning trial 150
INFO:root:Loading model unet++ with settings {'in_channels': 4, 'classes': 1, 'activation': 'sigmoid'}
INFO:root:Loading loss smooth
INFO:root:Loading loss smooth
INFO:echo.src.base_objective:Saving trial 150 results to local file /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results/trial_results_29312.gusched01.csv
INFO:echo.src.base_objective:Merging trial results and saving to /glade/work/kdagon/s2sml/results_week3_SH_510/trial_results.csv
[32m[I 2023-05-11 22:44:00,169][0m Trial 150 finished with values: [0.9563385355289835, 0.3300474103928613, 0.6180548886821368] and parameters: {'learning_rate': 0.0010748279727402954, 'norm': 'minmax', 'weight_decay': 0.000572774199384401, 'train_batch_size': 22, 'training_loss': 'logcosh', 'model_name': 'unet++'}. [0m
WARNING:root:Stopping early since the longest observed run-time in the study exceeds the time remaining on this node.
